{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CwZSA7MHodFs"
   },
   "source": [
    "# PRACTICA GUIADA 1: Métricas de evaluación de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0tFGZxUtodFv"
   },
   "source": [
    "## 1. Introducción\n",
    "\n",
    "El objetivo de esta práctica es analizar en la práctica las medidas de evaluación para modelos de clasificación mencionadas.\n",
    "\n",
    "Para ello trabajaremos tratando de predecir la probabilidad de que un empleado deje la empresa. Para ello se dispone de un dataset \n",
    "\n",
    "Los campos incluidos son:\n",
    "\n",
    "1. Última evaluación\n",
    "2. Cantidad de proyectos en los que trabajó\n",
    "3. Promedio de horas mensuales trabajadas\n",
    "4. Tiempo en la compañía\n",
    "5. Sufrió un accidente de trabajo\n",
    "6. Tuvo una promoción en el último año\n",
    "7. Nivel salarial\n",
    "\n",
    "El objetivo, entonces, es predecir la probabilidad de que $P(left=1 | X)$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0QlW2D_nodFw"
   },
   "source": [
    "## 2. Métricas de evaluación para problemas de clasificación\n",
    "\n",
    "Como de costumbre, importamos los datos y el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c_0aKXUbodFx"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QvGHmOMEodF5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>sales</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6671</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.42</td>\n",
       "      <td>3</td>\n",
       "      <td>189</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hr</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7398</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.76</td>\n",
       "      <td>4</td>\n",
       "      <td>158</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>IT</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7384</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2</td>\n",
       "      <td>139</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>support</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11440</th>\n",
       "      <td>0.69</td>\n",
       "      <td>0.48</td>\n",
       "      <td>5</td>\n",
       "      <td>232</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8575</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.59</td>\n",
       "      <td>4</td>\n",
       "      <td>197</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11553</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.55</td>\n",
       "      <td>3</td>\n",
       "      <td>164</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13199</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.86</td>\n",
       "      <td>4</td>\n",
       "      <td>266</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>RandD</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8024</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.37</td>\n",
       "      <td>3</td>\n",
       "      <td>137</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13561</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.61</td>\n",
       "      <td>3</td>\n",
       "      <td>148</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>management</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8736</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.85</td>\n",
       "      <td>2</td>\n",
       "      <td>156</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hr</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       satisfaction_level  last_evaluation  number_project  \\\n",
       "6671                 0.95             0.42               3   \n",
       "7398                 0.96             0.76               4   \n",
       "7384                 0.53             0.43               2   \n",
       "11440                0.69             0.48               5   \n",
       "8575                 0.83             0.59               4   \n",
       "11553                0.96             0.55               3   \n",
       "13199                0.32             0.86               4   \n",
       "8024                 0.52             0.37               3   \n",
       "13561                0.53             0.61               3   \n",
       "8736                 0.63             0.85               2   \n",
       "\n",
       "       average_montly_hours  time_spend_company  Work_accident  left  \\\n",
       "6671                    189                   2              1     0   \n",
       "7398                    158                   3              0     0   \n",
       "7384                    139                   3              0     0   \n",
       "11440                   232                   4              0     0   \n",
       "8575                    197                   4              0     0   \n",
       "11553                   164                   3              0     0   \n",
       "13199                   266                   4              0     0   \n",
       "8024                    137                   4              0     0   \n",
       "13561                   148                  10              0     0   \n",
       "8736                    156                   3              1     0   \n",
       "\n",
       "       promotion_last_5years       sales  salary  \n",
       "6671                       0          hr  medium  \n",
       "7398                       0          IT     low  \n",
       "7384                       0     support    high  \n",
       "11440                      0       sales  medium  \n",
       "8575                       0       sales  medium  \n",
       "11553                      0       sales  medium  \n",
       "13199                      0       RandD     low  \n",
       "8024                       0       sales     low  \n",
       "13561                      0  management    high  \n",
       "8736                       0          hr  medium  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Data/HR_comma_sep.csv')\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rot9noDDodF-"
   },
   "source": [
    "Armamos la matriz de predictores ($X$) y el target ($y$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jgBldKuqodF_"
   },
   "outputs": [],
   "source": [
    "train_cols = ['satisfaction_level', 'last_evaluation', 'number_project', 'average_montly_hours', \n",
    "              'time_spend_company', 'Work_accident', 'promotion_last_5years']\n",
    "X = df[train_cols]\n",
    "y = df['left']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X44KTzoYodGE"
   },
   "source": [
    "Hacemos el split entre train y test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ASmadC_CodGF"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cMD7-EfiojjT"
   },
   "outputs": [],
   "source": [
    "# Utilizamos sklearn para estandarizar la matriz de Features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_-hjDmzSodGJ"
   },
   "source": [
    "### 2.1 Entrenando un primer clasificador\n",
    "\n",
    "Como primer paso (y para mantener el problema simple) comencemos entrenando una regresión logística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IxXOvhBXodGM"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mbeati\\AppData\\Local\\Continuum\\anaconda3\\envs\\dsdh2\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10000000000.0, class_weight=None, dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(C=1e10)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ug2BfwQhosst"
   },
   "outputs": [],
   "source": [
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gMHgBvoPodGQ"
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FXdgfFJwodGU"
   },
   "source": [
    "### 2.2 Métricas: Accuracy\n",
    "\n",
    "Como recordarán, el accuracy se calcula como la proporción samples correctamente clasificados sobre el total de samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WffujvCSodGW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy= 0.756969696969697\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy=', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "53GnyAnoodGb"
   },
   "source": [
    "Es decir, que en este caso, encontramos que el 76% de los casos -en el test set- han sido correctamente clasificados.\n",
    "\n",
    "Ahora bien, ¿qué tan bueno es este clasificador? ¿Qué significa que podamos clasificar correctamente a esta proporción de casos?\n",
    "\n",
    "Una primera forma de comenzar a responder esta pregunta es comparar la performance con un clasificador bien simple y (casi) trivial: se lo suele llamar \"clasificador nulo\" y consiste simplemente en predecir solamente teniendo en cuenta la clase más frecuente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iZYl7ulVodGd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3769\n",
       "1    1181\n",
       "Name: left, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YKU2HDjWodGk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2385858585858586"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UwyWDqx3odGp"
   },
   "source": [
    "Es decir que 23% de los casos en el train-set son 1, es decir, se irán de la empresa. Por ende, la proporción de 0 (es decir, casos que no se van de la empresa) será:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qactLjb4odGq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7614141414141414"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.0 - y_test.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WjA4WUItodHG"
   },
   "source": [
    "Nuestro modelo simple, entonces, haría predicciones siempre igual a cero. Si realizáramos las predicciones en función de este dato... ¿qué accuracy esperaríamos obtener...? En efecto, esperaríamos obtener una accuracy cercana al 76%. Es decir, esperaríamos estar en lo correcto (sin ninguna otra informacion) en un 76% de los casos.\n",
    "\n",
    "De esta forma, pareciera que el modelo de regresión logística no es tan bueno: no parece mejorar demasiado respecto al modelo simple. Si solamente consideráramos el accuracy podríamos habernos equivocado en la evaluación de nuestro modelo. Por eso suele ser útil considerar otras métricas de evaluación. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f6-ARuH3odHH"
   },
   "source": [
    "### 2.3 Métricas: Confusion Matrix\n",
    "\n",
    "Si bien hemos estado trabajando con este insumo, hasta aquí lo veníamos haciendo de forma intuitiva. Tratemos de entender mejor qué es una matriz de confusión.\n",
    "\n",
    "Básicamente, es una tabla de contingencia que tabula la distribución de los casos analizados en función de su valor real (\"observado\") y su valor estimado por el modelo (\"predicho\"). \n",
    "\n",
    "En `confusion_matrix` es importante recordar que el primer arugmento corresponde a los valores observados y el segundo a los valores predichos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "okm6PpSPodHJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3464  305]\n",
      " [ 898  283]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zuPYTdS5odHN"
   },
   "source": [
    "En las filas están representados los datos observados (`y_test`). En las columnas se representan los datos predichos por el modelo (`y_pred`).\n",
    "\n",
    "** Matriz de confusión **\n",
    "\n",
    "|                        | Pred Stay ($y\\_pred=0$)| Pred Left ($y\\_pred=1$)| Total|\n",
    "| :--------------------  |:----------------------:| :---------------------:|-----:|\n",
    "| Obs Stay ($y\\_test=0$) | 3465                   | 304                    |3769  |\n",
    "| Obs Left ($y\\_test=1$) | 898                    | 283                    |1181  | \n",
    "| Total                  | 4363                   | 587                    |N=4950|\n",
    "     \n",
    "Ahora bien, cada casilla aporta información sobre la performace del clasificador:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HXUIfsNYodHP"
   },
   "source": [
    "* **True Positives (TP):** hemos predicho correctamente que el empleado se va (295)\n",
    "* **True Negatives (TN):** hemos predicho correctamente que el empleado se queda (3497)\n",
    "* **False Positives (FP):** hemos predicho que el empleado se iba pero se queda (265)\n",
    "* **False Negatives (FN):** hemos predicho que el empleado se queda pero se va (893)\n",
    "\n",
    "Asignemos a variables estos casos para realizar algunos cálculos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5545DRYpodHP"
   },
   "outputs": [],
   "source": [
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b_7T8FTkodHV"
   },
   "source": [
    "### 2.4 Métricas computadas desde la matriz de confusión: Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GxBIbzp-odHX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.756969696969697\n",
      "0.756969696969697\n"
     ]
    }
   ],
   "source": [
    "print((TP + TN) / float(TP + TN + FP + FN))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vOXKa28NodHb"
   },
   "source": [
    "### 2.5 Métricas computadas desde la matriz de confusión: Classification Error\n",
    "\n",
    "Es, básicamente, el complemento de accuracy. Cuantifica el error total cometido por el clasificador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5KNlj6jhodHc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24303030303030304\n",
      "0.24303030303030304\n"
     ]
    }
   ],
   "source": [
    "class_error = (FP + FN) / float(TP + TN + FP + FN)\n",
    "\n",
    "print(class_error)\n",
    "print(1 - accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BCt84lk8odHg"
   },
   "source": [
    "### 2.6 Métricas computadas desde la matriz de confusión: Sensitivity (o recall)\n",
    "\n",
    "Mide la capacidad (qué tan \"sensible\" es) del modelo de detectar los verdaderos positivos (TP) sobre todos los casos que son positivos (FN + TP). En nuestro ejemplo: del total de personas que se van, ¿cuántas logra clasificar correctamente el modelo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TkZpUKwDodHi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23962743437764605\n",
      "0.23962743437764605\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "sensitivity = TP / float(FN + TP)\n",
    "\n",
    "print(sensitivity)\n",
    "print(recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xw6QhU_JodHn"
   },
   "source": [
    "### 2.7 Métricas computadas desde la matriz de confusión: Specificity\n",
    "\n",
    "Mide la capacidad de detectar los \"verdaderos negativos\" (TN) sobre el total de casos que son negativos (TN + FP). ¿Qué tan específico o selectivo es el modelo al predecir las instancias positivas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ssKgGy5IodHo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9190766781639692\n"
     ]
    }
   ],
   "source": [
    "specificity = TN / (TN + FP)\n",
    "\n",
    "print(specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5LT5XJalodHs"
   },
   "source": [
    "Nuestro modelo parece ser muy específico y poco sensitivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Efu8iasodHu"
   },
   "source": [
    "### 2.8 Métricas computadas desde la matriz de confusión: Precision\n",
    "\n",
    "Mide qué tan \"preciso\" es el clasificador al predecir las instancias positivas. Es decir, cuando el clasificador predice un valor positivo... ¿qué tan frecuentemente es esta predicción correcta?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W2MlMFJwodHx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4812925170068027\n",
      "0.4812925170068027\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = TP / float(TP + FP)\n",
    "\n",
    "print(precision)\n",
    "print(precision_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YvpCecljodH0"
   },
   "source": [
    "### 2.9 Métricas computadas desde la matriz de confusión: F1-Score\n",
    "\n",
    "Es un promedio armónimo entre precision y recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D8-Gjvw-odH3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3199547767100056\n",
      "0.3199547767100056\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1 = 2*((precision*sensitivity)/(precision+sensitivity))\n",
    "\n",
    "print(f1)\n",
    "print(f1_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jLpEdrYcodH7"
   },
   "source": [
    "### 3. Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q9JGhP5hodH9"
   },
   "source": [
    "La matriz de confusión brinda un panorama más completo sobre la performance del clasificador. \n",
    "\n",
    "¿Sobre qué métricas habría que focalizarse? Obviamente, depende del problema, del objetivo.\n",
    "\n",
    "* **Ejemplo - filtro de SPAM:** pareciera que los FN son más aceptables (spam entra en la casilla) que los FP (un mail útil es filtrado como SPAM).\n",
    "\n",
    "\n",
    "* **Ejemplo - detector de fraudes:** en este caso, pareciera ser preferible tolerar FP (transacciones que NO son falsas como falsas) que dejar pasar TP (transacciones fraudulentas que no son detectadas). Sería preferible minimizar sensitivity."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "1.PRACTICA_GUIADA_Métricas_Evaluación.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
