{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7yO4fvwhyhvk"
   },
   "source": [
    "# PRÁCTICA GUIADA: Random Forest y ExtraTrees en Scikit Learn\n",
    "\n",
    "## 1. Introducción\n",
    "En esta práctica vamos a comparar el rendimiento de los siguientes algoritmos:\n",
    "\n",
    "- Árboles de decisión\n",
    "- Bagging sobre Árboles de decisión\n",
    "- Random Forest\n",
    "- Extra Trees\n",
    "\n",
    "Para ello vamos a comenzar con la lectura del dataset de aceptabilidad de autos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jScdVG1wyhvm",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "buying           object\n",
       "maint            object\n",
       "doors            object\n",
       "persons          object\n",
       "lug_boot         object\n",
       "safety           object\n",
       "acceptability    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv('../Data/car.csv') # Revisar el path\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q3YsInLayhvs"
   },
   "source": [
    "Esta vez vamos a codificar los atributos usando un esquema One Hot, es decir, los consideraremos como variables categóricas. También vamos a codificar el target usando el `LabelEncoder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BnIuS5w9yhvu",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lab_enc = LabelEncoder()\n",
    "lab_enc.fit(df['acceptability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FsgZYvLOyhvy",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying_high</th>\n",
       "      <th>buying_low</th>\n",
       "      <th>buying_med</th>\n",
       "      <th>buying_vhigh</th>\n",
       "      <th>maint_high</th>\n",
       "      <th>maint_low</th>\n",
       "      <th>maint_med</th>\n",
       "      <th>maint_vhigh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   buying_high  buying_low  buying_med  buying_vhigh  maint_high  maint_low  \\\n",
       "0            0           0           0             1           0          0   \n",
       "1            0           0           0             1           0          0   \n",
       "2            0           0           0             1           0          0   \n",
       "3            0           0           0             1           0          0   \n",
       "4            0           0           0             1           0          0   \n",
       "\n",
       "   maint_med  maint_vhigh  \n",
       "0          0            1  \n",
       "1          0            1  \n",
       "2          0            1  \n",
       "3          0            1  \n",
       "4          0            1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = lab_enc.transform(df['acceptability'])\n",
    "X = pd.get_dummies(df.drop('acceptability', axis=1))\n",
    "\n",
    "X.iloc[:,0:8].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos el split entre train y test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_NC7Ei-ryhv1"
   },
   "source": [
    "Para que los resultados sean consistentes hay que exponer los modelos exactamente al mismo esquema de validación cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j0pXpjNFyhv3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "cv = StratifiedKFold(n_splits=3, random_state=41, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nxxMJeMYyhv5"
   },
   "source": [
    "## 2. Comparando la performance de los árboles de decisión y ensambles de modelos\n",
    " \n",
    "Ahora vamos a inicializar el clasificador de árbol de decisión, evaluar su rendimiento y compararlo con la perfomance de los ensambles que hemos visto hasta aquí. Para ello, vamos a usar los siguientes métodos:\n",
    "\n",
    "### RandomForestClassifier()\n",
    "\n",
    "Este método implementa y ejectua un RandomForest para resolver un problema de clasificación. Algunos de los parámetros más importantes son los siguientes:\n",
    "\n",
    "* `n_estimators`: el número de iteraciones (o sea, de `base_estimators`) para entrenar\n",
    "* `criterion`: define el criterio de impureza para evaluar la calidad de las particiones (por defecto, es `gini`) \n",
    "* `max_features`: la cantidad de features que extraerá para entrenar cada `base_estimator`. Por default es igual a `sqrt(X.shape[1])`\n",
    "* `bootstrap` y `bootstrap_features`: controla si tanto los n_samples como las features son extraidos con reposición.\n",
    "* `max_depth`: la pronfundidad máxima del árbol\n",
    "* `min_samples_leaf`: el número mínimo de n_samples para constituir una hoja del árbol (nodo terminal)\n",
    "* `min_samples_split`: el número mínimo de n_samples para realizar un split.\n",
    "\n",
    "y varios otros que pueden llegar a ser importantes al momento de realizar el tunning. En general, los más importantes suelen ser: `n_estimators`, `max_features`, `max_depth` y `min_samples_leaf`.\n",
    "\n",
    "\n",
    "### ExtraTreesClassifier()\n",
    "\n",
    "Con este método se puede estimar un conjunto de conjuntos de árboles de decisión randomizados. Toma los mismos parámetros que `RandomForestClassifier()`.\n",
    "\n",
    "\n",
    "### BaggingClassifier()\n",
    "\n",
    "Este método es muy interesante porque, a diferencia de los anteriores, es un \"meta estimador\", está situado en nivel de abstracción mayor. Es decir, que permite implementar el algoritmo de bagging (para clasificación) con casi cualquier estimador de Scikit-Learn. Toma como parámetros análogos a los dos métodos anteriores (con diferentes valores por defecto en algunos casos). Los únicos \"nuevos\" son: \n",
    "\n",
    "* `base_estimator`: el estimador sobre el cual queremos correr el bagging (regresiones, árboles, etc...)\n",
    "* `max_samples`: la cantidad de n_samples que muestrea en cada iteración. Por default es igual a `sqrt(X.shape[0])`\n",
    "\n",
    "\n",
    "Para comparar los diferentes algoritmos armamos la siguiente función. Toma como input un estimador y un string con el nombre que le quieran poner, y ejecuta un `cross_val_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V7Br9N3Jyhv6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento de Árbol de decisión:\t0.944 ± 0.008\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier\n",
    "\n",
    "\n",
    "def evaluar_rendimiento(modelo, nombre, X_train, y_train, cv):\n",
    "    s = cross_val_score(modelo, X_train, y_train, cv=cv, n_jobs=-1)\n",
    "    print(\"Rendimiento de {}:\\t{:0.3} ± {:0.3}\".format( \\\n",
    "        nombre, s.mean().round(3), s.std().round(3)))\n",
    "    \n",
    "    \n",
    "dt = DecisionTreeClassifier(class_weight='balanced', random_state=1)\n",
    "\n",
    "evaluar_rendimiento(dt,\"Árbol de decisión\", X_train, y_train, cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SRboBhh3yhv8"
   },
   "source": [
    "Ahora probamos con los modelos restantes y evaluamos el rendimiento.  \n",
    " * Bagging de Árboles de decisión\n",
    " * RandomForest\n",
    " * ExtraTrees\n",
    "\n",
    "Sería recomendable que vean la documentación para ver qué parámetros aceptan.   \n",
    "http://scikit-learn.org/stable/modules/ensemble.html#forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "myVgGdMZyhv8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento de Árbol de decisión:\t0.944 ± 0.008\n",
      "Rendimiento de Bagging AD:\t0.948 ± 0.012\n",
      "Rendimiento de Random Forest:\t0.915 ± 0.009\n",
      "Rendimiento de Extra Trees:\t0.939 ± 0.012\n"
     ]
    }
   ],
   "source": [
    "bdt = BaggingClassifier(dt, random_state=1)\n",
    "rf = RandomForestClassifier(class_weight='balanced', random_state=1)\n",
    "et = ExtraTreesClassifier(class_weight='balanced', random_state=1)\n",
    "\n",
    "evaluar_rendimiento(dt,  \"Árbol de decisión\", X_train, y_train, cv)\n",
    "evaluar_rendimiento(bdt, \"Bagging AD\", X_train, y_train, cv)\n",
    "evaluar_rendimiento(rf,  \"Random Forest\", X_train, y_train, cv)\n",
    "evaluar_rendimiento(et,  \"Extra Trees\", X_train, y_train, cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eea1n5Xhyhv_"
   },
   "source": [
    "En este caso, el bagging de árboles de decisión anda mejor que el resto.   \n",
    "Con otros set de datos, los modelos Random Forest y Extra Trees podrían tener mejores resultados y merecen ser probados. Podríamos implementar un gridsearh para intentar realizar un tunning de los hiperparámetros..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Xf3I9qkyhv_"
   },
   "source": [
    "## 3. Tuneando los hiperparámetros de RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EQTH_EynyhwA",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_trees = {'n_estimators': [50, 100, 200], \n",
    "               'max_features': [1, 5, 8, 10, 21], \n",
    "               'max_depth': [5, 20, 50, 70, 100], \n",
    "               'min_samples_leaf':[1, 5, 8, 10, 50]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FDHh1p0KyhwH",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_search_rf = GridSearchCV(rf, param_grid=param_trees, cv=cv, verbose=1, n_jobs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6EwcgKH1yhwI",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 375 candidates, totalling 1125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=3)]: Done 194 tasks      | elapsed:   14.0s\n",
      "[Parallel(n_jobs=3)]: Done 444 tasks      | elapsed:   31.6s\n",
      "[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed:   57.4s\n",
      "[Parallel(n_jobs=3)]: Done 1125 out of 1125 | elapsed:  1.4min finished\n",
      "C:\\Users\\mbeati\\AppData\\Local\\Continuum\\anaconda3\\envs\\dsdh2\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=41, shuffle=True),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                              class_weight='balanced',\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=None,\n",
       "                                              oob_score=False, random_state=1,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='warn', n_jobs=3,\n",
       "             param_grid={'max_depth': [5, 20, 50, 70, 100],\n",
       "                         'max_features': [1, 5, 8, 10, 21],\n",
       "                         'min_samples_leaf': [1, 5, 8, 10, 50],\n",
       "                         'n_estimators': [50, 100, 200]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ObRVsWZVyhwL",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=20, max_features=21,\n",
       "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=200, n_jobs=None, oob_score=False,\n",
       "                       random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ilu3TGtfyhwO"
   },
   "source": [
    "Puede verse que realizando un proceso de tunnig es ahora RandomForest el algoritmo que mejora la perfomance de los clasificadores comparados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento de Random Forest GS:\t0.964 ± 0.012\n"
     ]
    }
   ],
   "source": [
    "evaluar_rendimiento(grid_search_rf.best_estimator_,  \"Random Forest GS\", X_train, y_train, cv)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "1.PRACTICA_GUIADA_RandomForest_ExtraTrees..ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
