{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRACTICA INDEPENDIENTE: REDUCCIÓN DE DIMENSIONALIDAD DEL DATASET DE CARAS\n",
    "\n",
    "Manifold learning es usado habitualmente para entender la relación entre datos de alta dimensionalidad. Un caso muy común es el análisis de imágenes: por ejemplo, un set de imágenes con 1000 pixels cada una puede ser pensado como una colección de puntos en 1000 dimensiones -el brillo de cada pixel en cada imágen define la coordenada en esa dimensión.\n",
    "\n",
    "En esta práctica trabajaremos con un [dataset de imágenes de caras](http://vis-www.cs.umass.edu/lfw/). El dataset se llama \"Labeled Faces in the Wild\" y es una base de datos para trabajar con reconcimiento de rostors. Contiene alrededor de 13000 imágenes recolectadas de la web. Cada cara fue taggeada con el nombre de la persona. Utilizaremos las técnicas aprendidas para reducir la dimensionalidad de las imágenes y poder visualizarlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos las librerías que vamos a necesitar para trabajar.\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import joblib\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "#Importamos el dataset \n",
    "faces = joblib.load(\"faces_p2.dump\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota Importante:** el dataset está en almacenado en un objeto Bunch, que es un objeto tipo diccionario pero al que se accede a sus llaves como si fueran atributos. \n",
    "\n",
    "Podemos acceder a las imagenes de dos formas, con *faces.data* y con *faces.images*. \n",
    "\n",
    "En *face.images*, se mantiene el formato de la imagen, es decir que vamos a tener un array de 2D para cada imagen más una dimensión para almacenar cada foto. En *faces.data* los datos están vectorizados para poder usarlos como input de un modelo. Se rompe la estructura 2D de la foto y tenemos solamente una dimensión para cada imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "62*47"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos 2.370 imágenes cada una con 2.914 pixels. En otras palabras, podemos pensar estas imágenes como puntos en un espacio de 2.914 dimesiones.\n",
    "\n",
    "Hagamos una visualización rápida de algunas imágenes para ver con qué estamos trabajando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4, 8, subplot_kw=dict(xticks=[], yticks=[]))\n",
    "for i, axi in enumerate(ax.flat):\n",
    "    axi.imshow(faces.images[i], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos gustaría poder representar estas imágenes (que están en un espacio 2.914-dimensional) en menor dimensionalidad para poder aprender las relaciones fundamentales entre las imágenes. Una primera forma simple de comenzar sería computar en PCA y examinar la razón de variancia explicada, que nos daría una idea de cuántos componentes principales se requieren para poder describir estos datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: fitear un modelo de PCA conservando 100 componentes principales y plotear \n",
    "# el % de varianza explicada en función de la cantidad de componentes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que para este dataset alrededor de 100 componentes principales son necesarios para preservar el 90% de la varianza. Esto nos dice que, en principio, este dataset que es altamente multidimensional no puede ser descripto con pocos componentes lineales (que se obtienen a partir de la X original multiplicando por alguna matriz). \n",
    "\n",
    "Cuando este es el caso, métodos de manifold learning como T-SNE o IsoMap pueden ser de mucha ayuda. \n",
    "\n",
    "De todos modos comencemos ploteando los datos usando PCA para ver los resultados que obtenemos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El output es una proyección bidensional de todas las imágenes de input. Para tener una mejor idea de qué nos está diciendo esta proyección, definamos una función que va a plotear thumbnails de las imágenes en las coordenadas de la proyección:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import offsetbox\n",
    "\n",
    "def plot_components(proj, images=None, ax=None,\n",
    "                    thumb_frac=0.05, cmap='gray'):\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "    ax = ax or plt.gca()\n",
    "    \n",
    "    ax.plot(proj[:, 0], proj[:, 1], '.k')\n",
    "    \n",
    "    if images is not None:\n",
    "        min_dist_2 = (thumb_frac * max(proj.max(0) - proj.min(0))) ** 2\n",
    "        shown_images = np.array([2 * proj.max(0)])\n",
    "        for i in range(proj.shape[0]):\n",
    "            dist = np.sum((proj[i] - shown_images) ** 2, 1)\n",
    "            if np.min(dist) < min_dist_2:\n",
    "                # don't show points that are too close\n",
    "                continue\n",
    "            shown_images = np.vstack([shown_images, proj[i]])\n",
    "            imagebox = offsetbox.AnnotationBbox(\n",
    "                offsetbox.OffsetImage(images[i], cmap=cmap),\n",
    "                                      proj[i])\n",
    "            ax.add_artist(imagebox)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: proyectar los datos en 2 dimensiones usando PCA \n",
    "# y usar la función para plotear los resultados. Comentar los resultados obtenidos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: proyectar los datos en 2 dimensiones usando IsoMap\n",
    "# y usar la función para plotear los resultados. Comentar los resultados obtenidos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: proyectar los datos en 2 dimensiones usando T-SNE\n",
    "# y usar la función para plotear los resultados. Comentar los resultados obtenidos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: investigar qué otras técnicas de Manifold Learning existen y \n",
    "# usarlas para graficar el dataset de caras."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
