{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U_vvRh-ejQSY"
   },
   "source": [
    "# PRÁCTICA GUIADA: Model Validation Workflow\n",
    "\n",
    "## Introducción\n",
    "\n",
    "El objetivo de esta práctica es recorrer y profundizar las diferentes partes de la etapa de \"Modelado\" en el flujo de trabajo de Data Science. En efecto, supongamos que ya hemos concluido la etapa de limpieza y preprocesamiento de los datos. El paso siguiente es comenzar la etapa de análisis y modelado de la información. Hay tres grandes tareas que serán habitualmente realizadas en esta etapa (no excluyentes entre sí, de hecho será habitual encarar las tres en simultáneo):\n",
    "\n",
    "* Realizar el proceso de tunning de los hiperparámetros\n",
    "* Evaluar la performance de un modelo\n",
    "* Evaluar la performance de varios modelos\n",
    "\n",
    "A continuación presentamos un esquema estilizado del proceso:\n",
    "\n",
    "#### Un esquema posible del proceso de estimación y modelado\n",
    "_______________________________________________________________________________________________________________\n",
    "\n",
    "1. Realizar una separación entre Train y Test Sets.\n",
    "\n",
    "2. Sobre el **set de entrenamiento (Train Set):** \n",
    "    \n",
    "    1. *Selección de los modelos a evaluar:* por ahora estamos trabajando sobre el de regresión modelo lineal y sus extensiones.\n",
    "    \n",
    "    2. *Proceso de Tunning de los Hiperparámetros:* hasta ahora hemos visto como primer hiperparámetro el $\\alpha$ para los modelos de regresión regularizados. Este proceso se realiza generalmente a partir de una estrategia de cross-validation.\n",
    "    \n",
    "    3. *Entrenamiento del modelo final:* Luego del proceso de selección y tunning de los hiperparámetros, es necesario realizar el entrenamiento final del modelo. Para ello, estimamos un modelo sobre el total del Training Set.\n",
    "    \n",
    "3. Sobre el **set de testing (Test Set):**\n",
    "       \n",
    "    1. Estimación del error de genealización del mejor modelo \n",
    "________\n",
    "\n",
    "En este LAB trabajaremos sobre estas diferentes etapas a partir de un dataset que busca modelar la progresión de la enfermedad diabetes. En efecto, el dataset contiene 10 variables fisiológicas (edad. sexo, índice de masa corporal y seis mediciones del plasma sanguíneo) medidas en 442 pacientes y un indicador de la progresión de la enfermedad luego de un año base.\n",
    "\n",
    "La idea será hacer predicciones sobre este indicador de progresión de la enfermedad, identificando los mejores modelos y los mejores predictores.\n",
    "\n",
    "Para ello, recorreremos los diferentes pasos de esta etapa.\n",
    "\n",
    "* En primer lugar, como siempre, importamos los diferentes paquetes a utilizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bYfjjxpXjQSb"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = 10, 10\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LassoCV, Ridge, RidgeCV\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5p6f_oBTjQSm"
   },
   "source": [
    "* Luego, cargamos el dataset y definimos los nombres de colmnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-fiuOYrhjQSo",
    "outputId": "355528e4-0ce8-4548-d4ae-011dfd5430cf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>map</th>\n",
       "      <th>tc</th>\n",
       "      <th>ldl</th>\n",
       "      <th>hdl</th>\n",
       "      <th>tch</th>\n",
       "      <th>ltg</th>\n",
       "      <th>glu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi       map        tc       ldl       hdl  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "        tch       ltg       glu  \n",
       "0 -0.002592  0.019908 -0.017646  \n",
       "1 -0.039493 -0.068330 -0.092204  \n",
       "2 -0.002592  0.002864 -0.025930  \n",
       "3  0.034309  0.022692 -0.009362  \n",
       "4 -0.002592 -0.031991 -0.046641  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = \"age sex bmi map tc ldl hdl tch ltg glu\".split()\n",
    "diabetes = datasets.load_diabetes()\n",
    "df = pd.DataFrame(diabetes.data, columns=columns)\n",
    "y = diabetes.target  # progresion de la enfermedad\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cZc6QDqwjQS4"
   },
   "source": [
    "* Pareciera que las variables ya están normalizadas. Lo verificamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VUE9p8WGjQS6",
    "outputId": "ef49a677-947e-4bfb-91d3-15fb1a09b1a7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>-3.634285e-16</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>1.308343e-16</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>-8.045349e-16</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>map</th>\n",
       "      <td>1.281655e-16</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tc</th>\n",
       "      <td>-8.835316e-17</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ldl</th>\n",
       "      <td>1.327024e-16</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hdl</th>\n",
       "      <td>-4.574646e-16</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tch</th>\n",
       "      <td>3.777301e-16</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ltg</th>\n",
       "      <td>-3.830854e-16</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glu</th>\n",
       "      <td>-3.412882e-16</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             mean       std\n",
       "age -3.634285e-16  0.047619\n",
       "sex  1.308343e-16  0.047619\n",
       "bmi -8.045349e-16  0.047619\n",
       "map  1.281655e-16  0.047619\n",
       "tc  -8.835316e-17  0.047619\n",
       "ldl  1.327024e-16  0.047619\n",
       "hdl -4.574646e-16  0.047619\n",
       "tch  3.777301e-16  0.047619\n",
       "ltg -3.830854e-16  0.047619\n",
       "glu -3.412882e-16  0.047619"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.apply(['mean','std']).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Efectivamente: \n",
    "    + $\\bar{x_{j}} \\approx 0$\n",
    "    \n",
    "    + $s_{j}=0.047619$\n",
    "  \n",
    " \n",
    "  \n",
    "* Revisamos la descripción del dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _diabetes_dataset:\n",
      "\n",
      "Diabetes dataset\n",
      "----------------\n",
      "\n",
      "Ten baseline variables, age, sex, body mass index, average blood\n",
      "pressure, and six blood serum measurements were obtained for each of n =\n",
      "442 diabetes patients, as well as the response of interest, a\n",
      "quantitative measure of disease progression one year after baseline.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "  :Number of Instances: 442\n",
      "\n",
      "  :Number of Attributes: First 10 columns are numeric predictive values\n",
      "\n",
      "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
      "\n",
      "  :Attribute Information:\n",
      "      - Age\n",
      "      - Sex\n",
      "      - Body mass index\n",
      "      - Average blood pressure\n",
      "      - S1\n",
      "      - S2\n",
      "      - S3\n",
      "      - S4\n",
      "      - S5\n",
      "      - S6\n",
      "\n",
      "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\n",
      "\n",
      "Source URL:\n",
      "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
      "\n",
      "For more information see:\n",
      "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
      "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n"
     ]
    }
   ],
   "source": [
    "print(diabetes.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering: creamos features de grado 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VJUVjiYzjQTJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((442, 10), (442, 65))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = PolynomialFeatures(2,include_bias=False,interaction_only=False).fit_transform(df)\n",
    "df.shape, X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PO7rTL6ljQTN"
   },
   "source": [
    "\n",
    "## Paso 1. Hacer la separación entre Train Set y Test Set\n",
    "\n",
    "Scikit-learn tiene una función que se encarga de la separación entre test y entrenamiento llamada `train_test_split`. El parámetro `test_size` indica la propoción de los datos que vamos a separar para hacer la evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0wib0BXwjQTO",
    "outputId": "eb4cc37d-e6ec-439f-b864-ac0742b4a310"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(309, 65) (309,)\n",
      "(133, 65) (133,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=53)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YgbCS9Z4jQTU"
   },
   "source": [
    "## SOBRE EL TRAIN SET\n",
    "### Paso 2A. Seleccionar los modelos a evaluar\n",
    "\n",
    "En este ejercicio probaremos tres modelos diferentes:\n",
    "    \n",
    "* regresión lineal (`LinearRegression()`)\n",
    "* regresión lineal regularizada Ridge (`Ridge()`, `RidgeCV()`)\n",
    "* regresión lineal regularizada LASSO (`Lasso()`, `LassoCV()`)\n",
    "\n",
    "Instanciemos, entonces, los modelos.\n",
    "\n",
    "Ahora bien, vamos a realizar el proceso de tunning de los hiperparámetros de los modelos en base a validación cruzada. Por eso, instanciamos previamente tres objetos:\n",
    "\n",
    "* un grid de diferentes valores $\\alpha$ para realizar el tunning de Ridge (`al_ridge`)\n",
    "* un grid de diferentes valores $\\alpha$ para realizar el tunning de Lasso (`al_lasso`)\n",
    "* un objeto que genera la partición del dataset en K partes para luego usar en el proceso de validación cruzada (`kf`). Al ejecutar `kf` el mismo provee los índices donde realizar el split del dataset. Notar que solamente instanciamos el `kf`. Luego, lo utilizaremos en la estimación de los hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gd1e7zlejQTV"
   },
   "outputs": [],
   "source": [
    "# Generamos un grid de $\\alpha$ para probar e instanciamos un particionador del Training Set \n",
    "# en K partes para realizar la validación cruzada\n",
    "\n",
    "al_ridge = np.linspace(0.001, 0.3, 300)\n",
    "al_lasso = np.linspace(0.1, 0.5, 300)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=12)\n",
    "\n",
    "# Instanciamos los modelos\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm_ridge_cv= RidgeCV(alphas=al_ridge, cv=kf, normalize=False)\n",
    "lm_lasso_cv = LassoCV(alphas=al_lasso, cv=kf, normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MjbA-1NFjQTa"
   },
   "source": [
    "* Luego, hacemos el fit de los tres estimadores, lo cual nos lleva a...\n",
    "\n",
    "### Paso 2B. Proceso de Tunning de Hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rWqx7x-SjQTb",
    "outputId": "a96226de-0ab5-4ceb-8ba0-a89fb8379d2b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LassoCV(alphas=array([0.1       , 0.10133779, 0.10267559, 0.10401338, 0.10535117,\n",
       "       0.10668896, 0.10802676, 0.10936455, 0.11070234, 0.11204013,\n",
       "       0.11337793, 0.11471572, 0.11605351, 0.1173913 , 0.1187291 ,\n",
       "       0.12006689, 0.12140468, 0.12274247, 0.12408027, 0.12541806,\n",
       "       0.12675585, 0.12809365, 0.12943144, 0.13076923, 0.13210702,\n",
       "       0.13344482, 0.13478261, 0.1361204 , 0.13745819, 0.13879599,\n",
       "       0.140133...\n",
       "       0.4812709 , 0.4826087 , 0.48394649, 0.48528428, 0.48662207,\n",
       "       0.48795987, 0.48929766, 0.49063545, 0.49197324, 0.49331104,\n",
       "       0.49464883, 0.49598662, 0.49732441, 0.49866221, 0.5       ]),\n",
       "        copy_X=True, cv=KFold(n_splits=5, random_state=12, shuffle=True),\n",
       "        eps=0.001, fit_intercept=True, max_iter=1000, n_alphas=100, n_jobs=None,\n",
       "        normalize=False, positive=False, precompute='auto', random_state=None,\n",
       "        selection='cyclic', tol=0.0001, verbose=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hacemos los fits respectivos\n",
    "lm.fit(X_train, y_train)\n",
    "lm_ridge_cv.fit(X_train, y_train)\n",
    "lm_lasso_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kNfz-_pfjQTh"
   },
   "source": [
    "Es importante tener en claro que sucedió al ejecutar esta celda.\n",
    "\n",
    "1. Hicimos un fit de un modelo de regresión lineal en el Training Set.\n",
    "2. Usando `lm_ridge_cv`, realizamos el proceso de tunning del $\\alpha$ en el modelo regularizado vía Ridge; a su vez, usamos el particionador `kf` con el que definimos que haríamos una Cross-Validation de K=5, haciendo un shuffle del dataset previamente.\n",
    "3. Usando `lm_lasso_cv`, realizamos el tunning del $\\alpha$ para el modelo LASSO (usando el mismo particionador `kf`)\n",
    "\n",
    "Veamos cuáles son los $\\alpha$ estimados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "anCt38a6jQTi",
    "outputId": "47d10f79-894c-4d91-c636-22fdf3b8cfdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha Ridge: 0.004 \n",
      "Alpha LASSO: 0.1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Alpha Ridge:',lm_ridge_cv.alpha_,'\\n'\n",
    "      'Alpha LASSO:',lm_lasso_cv.alpha_,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dc16HEcMjQTn"
   },
   "source": [
    "### Paso 2C. Estimación del modelo final sobre todo el Training Set\n",
    "\n",
    "Ya estamos en condiciones de realizar la estimación final de los modelos sobre los datos de Training Set, para luego realizar la validación final y seleccionar el modelo a utilizar.\n",
    "\n",
    "El modelo de regresión lineal (al no tener hiperparámetros) ya está listo. Lo que nos queda es seleccionar los hiperparámetros $\\alpha_{ridge}$ y $\\alpha_{lasso}$ que minimicen los errores cross-validados respectivos. En este punto, podríamos ejecutar el siguiente código para el caso del modelo Ridge:\n",
    "\n",
    "```python\n",
    "\n",
    "a = lm_ridge_cv.alpha_\n",
    "ridge_final = Ridge(a)\n",
    "ridge_final.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "* Buscamos el $\\alpha_{ridge}$ óptimo dentro del objeto `RidgeCV`.\n",
    "* Instanciamos el estimador `Ridge`.\n",
    "* Hacemos el fit. \n",
    "\n",
    "Con esto, tendríamos estimado el modelo, es decir... todos los parámetros, en este caso $\\beta_{i}$ regularizados. Luego, repetiríamos el mismo proceso para Lasso. \n",
    "\n",
    "Afortunadamente, Scikit-Learn tiene implementado este procedimiento dentro de los mismos estimadores `RidgeCV` y `LassoCV`. De esta forma, ya se hizo el \"fit\" con el $\\alpha$ mínimo en cada caso. Por esto, podemos llamar directamente al método `.predict` dentro de cada uno de los modelos.\n",
    "\n",
    "En este [link](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html) y en [este](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html) pueden consultar más en profundidad sobre los estimadores en cuestión...\n",
    "\n",
    "**NOTA:** Más adelante en el curso, veremos cómo \"encapsular\" estos procesos en un proceso más general que se llama [`GridSearchCV`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html), particularmente útil cuando tenemos muchos modelos a evaluar, con muchos hiperparámetros a tunear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MZgejptXjQTo"
   },
   "source": [
    "* Solamente por curiosidad, veamos qué performance tiene cada modelo en el Training Set.\n",
    "* Calculemos el $R^2$ y el MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MWswdrBujQTq",
    "outputId": "30a10988-ab97-453f-c4f5-223265ed2c8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Score Train Lineal: 0.62\n",
      " Score Train Ridge : 0.55\n",
      " Score Train Lasso : 0.50\n",
      "\n",
      " Train RMSE lineal   : 46.42 \n",
      " Train RMSE Ridge    : 50.72 \n",
      " Train RMSE Lasso    : 53.39 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculamos el R2\n",
    "\n",
    "print(\" Score Train Lineal: %.2f\\n\" % lm.score(X_train, y_train),\n",
    "      \"Score Train Ridge : %.2f\\n\" % lm_ridge_cv.score(X_train, y_train),\n",
    "      \"Score Train Lasso : %.2f\\n\" %  lm_lasso_cv.score(X_train, y_train))\n",
    "\n",
    "# Calculamos el RMSE\n",
    "\n",
    "y_pred_tr_lm = lm.predict(X_train)\n",
    "y_pred_tr_ridge = lm_ridge_cv.predict(X_train)\n",
    "y_pred_tr_lasso = lm_lasso_cv.predict(X_train)\n",
    "\n",
    "rmse = lambda y, y_pred: np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "print(\" Train RMSE lineal   : %.2f \\n\" % rmse(y_train,y_pred_tr_lm),\n",
    "      \"Train RMSE Ridge    : %.2f \\n\" % rmse(y_train,y_pred_tr_ridge),\n",
    "      \"Train RMSE Lasso    : %.2f \\n\" % rmse(y_train,y_pred_tr_lasso))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4qgm84CkjQT1"
   },
   "source": [
    "* ¿Cuáles son los parámetros de cada modelo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85.79953959962961,\n",
       " array([    51.889,   -277.931,    329.161,    408.838, -10879.143,\n",
       "          9304.575,   4102.95 ,    398.192,   4159.891,     63.607,\n",
       "          2934.339,   2601.91 ,  -2158.435,    748.513,  -6849.989,\n",
       "          -291.786,   7406.615,   5535.134,   4594.689,     10.862,\n",
       "            -1.678,   2429.966,   3543.026,   6127.881,  -5080.086,\n",
       "         -1083.759,  -1358.331,  -2968.45 ,    215.523,   1343.784,\n",
       "          2359.791, -18573.15 ,  18847.188,   2908.555,  -6154.991,\n",
       "          6084.878,   1095.892,    111.728,  24379.253, -13336.511,\n",
       "        -13497.03 ,  -8625.451,  -7366.977,  -4091.349,  47163.947,\n",
       "        -62611.502, -32079.872, -34318.915, -24061.883,   6282.181,\n",
       "         26112.234,  19995.948,  16280.057,   9985.092,  -6093.217,\n",
       "          3403.824,  11381.295,  12233.682,   2976.084,   7801.497,\n",
       "         12596.011,   5937.702,  21621.643,   -214.866,   1509.748]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "(lm.intercept_, lm.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "it4WyMaOjQT_",
    "outputId": "cd54197a-7550-4265-c8e6-658ca1387a7a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144.24560945671513,\n",
       " array([  25.376, -240.588,  473.598,  356.986, -569.13 ,  341.231,\n",
       "         130.949,  287.821,  611.191,   27.374,  788.305,  951.323,\n",
       "         -73.283,  506.988,   15.022, -192.054,   66.664,   17.361,\n",
       "         516.83 ,  257.767,   -1.453,  441.846,  662.01 ,  121.68 ,\n",
       "         -90.642,  364.671, -106.42 ,   12.284,  265.557,  590.469,\n",
       "         424.759, -109.136,  -25.85 ,  -60.06 ,   87.101,  108.086,\n",
       "         430.009,   59.725,  301.092,  382.578,  -83.078,   88.927,\n",
       "         198.725, -149.219,  276.64 ,  308.553,  390.953, -401.704,\n",
       "        -133.879,  410.752,  245.756,  142.038,   23.659,   29.135,\n",
       "         326.068,  -88.096,  -77.162,  452.469,  316.232,   35.438,\n",
       "        -525.554,   74.361,  -23.542,  236.016,  616.668]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lm_ridge_cv.intercept_,lm_ridge_cv.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pe26gXvljQUF",
    "outputId": "8826e595-15aa-4113-bbdb-68ba128115b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(151.84474705120286,\n",
       " array([   0.   , -159.794,  490.66 ,  305.282,   -0.   ,   -0.   ,\n",
       "        -181.009,   21.986,  441.617,    4.299,    0.   ,    0.   ,\n",
       "           0.   ,    0.   ,    0.   ,    0.   ,   -0.   ,    0.   ,\n",
       "           0.   ,    0.   ,   -0.   ,    0.   ,    0.   ,    0.   ,\n",
       "           0.   ,    0.   ,    0.   ,    0.   ,    0.   ,    0.   ,\n",
       "           0.   ,    0.   ,    0.   ,   -0.   ,    0.   ,    0.   ,\n",
       "           0.   ,    0.   ,    0.   ,    0.   ,   -0.   ,    0.   ,\n",
       "           0.   ,    0.   ,    0.   ,    0.   ,    0.   ,   -0.   ,\n",
       "          -0.   ,    0.   ,    0.   ,    0.   ,    0.   ,    0.   ,\n",
       "           0.   ,   -0.   ,   -0.   ,    0.   ,   -0.   ,    0.   ,\n",
       "          -0.   ,    0.   ,   -0.   ,    0.   ,    0.   ]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lm_lasso_cv.intercept_,lm_lasso_cv.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OQNadQuTjQUL"
   },
   "source": [
    "* ¿Cuáles son las variables más importantes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3gWJYEsKjQUN"
   },
   "source": [
    "## SOBRE TEST SET\n",
    "### Paso 3. Hacer la estimación del error de generalización del modelo\n",
    "\n",
    "Lo único que queda es evaluar la performance del modelo. Para ello debemos usar datos que no hayan formado parte del proceso de entrenamiento anterior. Usaremos, entonces, el Test Set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5N3lZrWGjQUO",
    "outputId": "893e4a39-fb88-4980-8a77-1abe4e1bbe17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Score Test Lineal: 0.38\n",
      " Score Test Ridge : 0.53\n",
      " Score Test Lasso : 0.51\n",
      "\n",
      " Test RMSE lineal= 63.52\n",
      " Test RMSE Ridge = 55.21\n",
      " Test RMSE Lasso = 56.49\n"
     ]
    }
   ],
   "source": [
    "# Hacemos las predicciones sobre la matriz de predictores del Test Set\n",
    "\n",
    "y_pred_lm = lm.predict(X_test)\n",
    "y_pred_ridge = lm_ridge_cv.predict(X_test)\n",
    "y_pred_lasso = lm_lasso_cv.predict(X_test)\n",
    "\n",
    "\n",
    "print(\" Score Test Lineal: %.2f\\n\" % lm.score(X_test, y_test),\n",
    "      \"Score Test Ridge : %.2f\\n\" % lm_ridge_cv.score(X_test, y_test),\n",
    "      \"Score Test Lasso : %.2f\\n\" %  lm_lasso_cv.score(X_test, y_test))\n",
    "\n",
    "# Testeo final del modelo sobre Test Set\n",
    "\n",
    "print(\" Test RMSE lineal= %.2f\\n\" % rmse(y_test, y_pred_lm),\n",
    "      \"Test RMSE Ridge = %.2f\\n\" %  rmse(y_test, y_pred_ridge),\n",
    "      \"Test RMSE Lasso = %.2f\" %  rmse(y_test, y_pred_lasso))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qi6p87bQjQUT"
   },
   "source": [
    "* ¿Con cuál se quedarían? ¿Cuál es el modelo que mejor performa? ¿Y el que peor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    " RMSE lineal= 63.52 (Train: 46.42)\n",
    " RMSE Ridge = 55.21 (Train: 50.72)\n",
    " RMSE Lasso = 56.49 (Train: 53.39)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x144 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(20,2)})\n",
    "sns.heatmap(pd.concat([df, pd.DataFrame(y, columns=['target'])], axis=1).corr().iloc[[-1]], annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uso del parámetro **Stratify** en la función train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/salary.dat.txt', delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sx</th>\n",
       "      <th>rk</th>\n",
       "      <th>yr</th>\n",
       "      <th>dg</th>\n",
       "      <th>yd</th>\n",
       "      <th>sl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>full</td>\n",
       "      <td>25</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>35</td>\n",
       "      <td>36350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>full</td>\n",
       "      <td>13</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>22</td>\n",
       "      <td>35350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>full</td>\n",
       "      <td>10</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>23</td>\n",
       "      <td>28200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>full</td>\n",
       "      <td>7</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>27</td>\n",
       "      <td>26775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>full</td>\n",
       "      <td>19</td>\n",
       "      <td>masters</td>\n",
       "      <td>30</td>\n",
       "      <td>33696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sx    rk  yr         dg  yd     sl\n",
       "0    male  full  25  doctorate  35  36350\n",
       "1    male  full  13  doctorate  22  35350\n",
       "2    male  full  10  doctorate  23  28200\n",
       "3  female  full   7  doctorate  27  26775\n",
       "4    male  full  19    masters  30  33696"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 6)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sx</th>\n",
       "      <th>rk</th>\n",
       "      <th>yr</th>\n",
       "      <th>dg</th>\n",
       "      <th>yd</th>\n",
       "      <th>sl</th>\n",
       "      <th>sx_male</th>\n",
       "      <th>rk_associate</th>\n",
       "      <th>rk_full</th>\n",
       "      <th>dg_masters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>full</td>\n",
       "      <td>25</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>35</td>\n",
       "      <td>36350</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>full</td>\n",
       "      <td>13</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>22</td>\n",
       "      <td>35350</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>full</td>\n",
       "      <td>10</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>23</td>\n",
       "      <td>28200</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>full</td>\n",
       "      <td>7</td>\n",
       "      <td>doctorate</td>\n",
       "      <td>27</td>\n",
       "      <td>26775</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>full</td>\n",
       "      <td>19</td>\n",
       "      <td>masters</td>\n",
       "      <td>30</td>\n",
       "      <td>33696</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sx    rk  yr         dg  yd     sl  sx_male  rk_associate  rk_full  \\\n",
       "0    male  full  25  doctorate  35  36350        1             0        1   \n",
       "1    male  full  13  doctorate  22  35350        1             0        1   \n",
       "2    male  full  10  doctorate  23  28200        1             0        1   \n",
       "3  female  full   7  doctorate  27  26775        0             0        1   \n",
       "4    male  full  19    masters  30  33696        1             0        1   \n",
       "\n",
       "   dg_masters  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos variables \"dummy\"\n",
    "\n",
    "categories = ['sx', 'rk', 'dg']\n",
    "\n",
    "for category in categories:\n",
    "    serie = df[category]\n",
    "    dummies = pd.get_dummies(serie, drop_first= True, prefix=category)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos nuestra matriz de features y nuestro vector con la variable objetivo:\n",
    "\n",
    "X = df.drop(['sx', 'rk', 'dg', 'sl'], axis=1)\n",
    "y = df['sl']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos el split entre set de entrenamiento y de testeo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos un split entre train y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\\\n",
    "                                                    test_size=0.35, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución en set de entrenamiento\n",
      "1    0.787879\n",
      "0    0.212121\n",
      "Name: sx_male, dtype: float64\n",
      "\n",
      "\n",
      "Distribución en set de testeo\n",
      "1    0.631579\n",
      "0    0.368421\n",
      "Name: sx_male, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Distribución en set de entrenamiento')\n",
    "print(X_train['sx_male'].value_counts(normalize=True))\n",
    "print('\\n')\n",
    "print('Distribución en set de testeo')\n",
    "print(X_test['sx_male'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que las clases no se distribuyen de la misma forma en ambos sets. Podemos usar el parámentro stratify para lograr que ambos sets tengan la misma distribución:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\\\n",
    "                                                    test_size=0.35,\\\n",
    "                                                    stratify=X['sx_male'],\\\n",
    "                                                    random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución en set de entrenamiento\n",
      "1    0.727273\n",
      "0    0.272727\n",
      "Name: sx_male, dtype: float64\n",
      "\n",
      "\n",
      "Distribución en set de testeo\n",
      "1    0.736842\n",
      "0    0.263158\n",
      "Name: sx_male, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Distribución en set de entrenamiento')\n",
    "print(X_train['sx_male'].value_counts(normalize=True))\n",
    "print('\\n')\n",
    "print('Distribución en set de testeo')\n",
    "print(X_test['sx_male'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comentarios**:\n",
    "    \n",
    "  * Esta funcionalidad de la función de train-test split va a ser fundamental para hacer el split en problemas de clasificación cuando las clases están desbalanceadas. En ese caso vamos a pasar a la variable objetivo \"y\" como criterio de estratificación.\n",
    "  * En el caso de aplicarlo a features, estratificar de acuerdo a una feature va a afectar la distribución de las demás, por lo que es un tema a tener en cuenta.\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "1.PRACTICA_GUIADA_Test_Training.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
