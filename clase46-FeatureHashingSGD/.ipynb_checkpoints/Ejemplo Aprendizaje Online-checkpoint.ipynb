{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objetivo\n",
    "\n",
    "Presentar código que sirva como \"template\" o punto de partida para diseñar soluciones no triviales para aprendizaje basado en grandes escalas de datos (tanto en $n$ como en $p$).\n",
    "\n",
    "Mostramos:\n",
    "* Cómo aprender (y validar) progresivamente de un flujo masivo y continuo de datos (hasta billones de observaciones diarias) aprovechando la interfaz `partial_fit` de los estimadores SGD.\n",
    "* Cómo crear interacciones ricas de variables categóricas y numéricas en estructuras muy \"sparse\" (potencialmente con millones de columnas).\n",
    "* Cómo combatir la alta dimensionalidad resultante mediante el \"hashing trick\" y la regularización.\n",
    "* Cómo despachar trabajos entre procesos y coordinarlos mediante archivos y estructuras elementales de IPC (inter-process communication) para explotar el paralelismo inherente a la selección de modelos.\n",
    "* Cómo administrar eficientemente la memoria evitando cargar todos los datos y/o estimadores al mismo tiempo.\n",
    "\n",
    "Notar que `GridSearchCV` no funciona con `partial_fit` ni validación progresiva, por lo que vamos a realizar una parte del trabajo a mano. Pero no será de gusto nada más, porque es importante tener algún contacto con las funcionalidades de multiprocesamiento y multithreading básicas, ya que en la práctica suelen presentarse situaciones que no son \"de manual\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inicialización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shelve\n",
    "import operator\n",
    "\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "from itertools import count, product as iproduct\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import log_loss, mean_squared_error\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuración\n",
    "\n",
    "* `in_paths` es la lista de archivos de entrada.\n",
    "\n",
    "* `out_path` es el shelve donde se guardan los scores y pipelines resultantes del fit.\n",
    "\n",
    "* `gen_path` y `gen_size` indican el archivo y el tamaño de los datos de prueba simulados por el generador de números aleatorios.\n",
    "\n",
    "* `n_jobs` es el número de procesos a correr en paralelo.\n",
    "\n",
    "* `use_squared_loss` debe ser `True` para usar score $-rss$ o `False` para $-logloss$.\n",
    "\n",
    "* `batch_size` es el tamaño de cada minibatch.\n",
    "\n",
    "* `n_batches` es la cantidad de minibatches que se leen al mismo tiempo desde el archivo de entrada.\n",
    "\n",
    "* `drop_scores` es el porcentaje de scores de minibatches iniciales a descartar. Con el resto se calcula el score medio.\n",
    "\n",
    "* `grid` es una lista de diccionarios cada uno de los cuales tiene tres entradas (`\"extractor\"`, `\"vectorizer\"`, `\"classifier\"`) cuyos valores son, a su vez, diccionarios indicando parámetros para la etapa correspondiente del pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_paths = ['data.csv']\n",
    "\n",
    "out_path = 'models.db'\n",
    "\n",
    "gen_path = 'data.csv'\n",
    "\n",
    "gen_size = 100000\n",
    "\n",
    "n_jobs = 8\n",
    "\n",
    "use_squared_loss = True\n",
    "\n",
    "batch_size = 1000\n",
    "\n",
    "n_batches = 20\n",
    "\n",
    "drop_scores = 0.7\n",
    "\n",
    "grid = [dict(extractor=dict(features=features),\n",
    "             vectorizer=dict(n_features=n_features, degree=degree),\n",
    "             classifier=dict(loss='log', max_iter=1000, tol=1e-3,\n",
    "                             l1_ratio=l1_ratio, alpha=alpha))\n",
    "        for features in [['x1', 'x2'], ['x1', 'x2', 'x3']]\n",
    "        for n_features in [2**20, 2**21, 2**22]\n",
    "        for degree in [1, 2]\n",
    "        for l1_ratio in [0.15, 0.5, 0.85]\n",
    "        for alpha in [0.0001, 0.001, 0.01, 0.1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generación de datos de prueba\n",
    "\n",
    "La siguiente celda genera datos de prueba en base a un modelo logístico de tres variables, sus cuadrados, sus interacciones y un intercept. Cada variable se distribuye de forma $N(0,1)$. Los 10 coeficientes se mueven de forma escalonada desde 0.9 (el intercept) hasta 0.1 (una de las interacciones) para facilitar la comparación con los coeficientes estimados por el classificador SGD. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "b0, b1, b2, b3, b12, b13, b23, b11, b22, b33 = reversed(\n",
    "    np.linspace(0.1, 0.9, 10))\n",
    "\n",
    "x1 = np.random.normal(size=gen_size)\n",
    "x2 = np.random.normal(size=gen_size)\n",
    "x3 = np.random.normal(size=gen_size)\n",
    "\n",
    "b = (b0 + b1 * x1 + b2 * x2 + b3 * x3 +\n",
    "     b12 * x1 * x2 + b13 * x1 * x3 + b23 * x2 * x3 +\n",
    "     b11 * x1**2 + b22 * x2**2 + b33 * x3**2)\n",
    "p = 1 / (1 + np.exp(-b))\n",
    "y = np.random.binomial(1, p)\n",
    "\n",
    "pd.DataFrame(dict(x1=x1, x2=x2, x3=x3, y=y)).to_csv(gen_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código principal\n",
    "\n",
    "Levanta varios procesos/jobs cada uno de los cuales corre la función `job` iterando sobre una parte de la grilla y fiteando un modelo por cada parametrización.\n",
    "\n",
    "Para ejecutarlo, correr la función `fit()` desde otra celda.\n",
    "\n",
    "Para inspeccionar los `n` mejores resultados, correr la función `results(n)` desde otra celda. Ojo que si `n` es grande se van a cargar muchos pipeline a la vez en memoria!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Extractor(FunctionTransformer):\n",
    "    \"\"\"\n",
    "    Extrae files de un DataFrame como diccionarios con atributos `features`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "        super().__init__(self._extract, validate=False)\n",
    "\n",
    "    def _extract(self, X):\n",
    "        return X.loc[:, self.features].to_dict('records')\n",
    "\n",
    "\n",
    "class Vectorizer(FeatureHasher):\n",
    "    \"\"\"\n",
    "    Vectoriza diccionarios de features teniendo en cuenta interacciones hasta\n",
    "    grado `degree`.\n",
    "    \n",
    "    Las potencias de dummies y las interacciones entre dummies provenientes de\n",
    "    la misma variable categórica no son incluidas.\n",
    "    \n",
    "    El resultado se hashea (hashing trick) en una tabla de tamaño 2**`n_features`.\n",
    "    No se guarda el mapa de features a hashes, este transformer es \"stateless\".\n",
    "    \n",
    "    Por defecto, cualquier valor que no sea de tipo `float` o `np.float64` se\n",
    "    considera categórico y se codifica como dummy. Otros tipos numéricos pueden\n",
    "    indicarse mediante el parámetro `num_types`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, degree=2, n_features=2**20,\n",
    "                 num_types=[float, np.float64]):\n",
    "        self.degree = degree\n",
    "        self.num_types = num_types\n",
    "        super().__init__(n_features=n_features)\n",
    "\n",
    "    def transform(self, X):\n",
    "        return super().transform(map(self._encode, X))\n",
    "\n",
    "    def _encode(self, dic):\n",
    "        dic = {k if type(v) in self.num_types else f'{k}={v}':\n",
    "               float(v) if type(v) in self.num_types else 1\n",
    "               for k, v in dic.items()}\n",
    "        dic_keys = list(dic.keys())\n",
    "        for deg in range(2, self.degree + 1):\n",
    "            for term_keys in iproduct(dic_keys, repeat=deg):\n",
    "                term_names, term_facts = [], []\n",
    "                for k, n in Counter(term_keys).items():\n",
    "                    v = dic[k]\n",
    "                    if type(v) is int and n > 1:\n",
    "                        break\n",
    "                    term_names.append(k if n == 1 else f'{k}^{n}')\n",
    "                    term_facts.append(v**n)\n",
    "                else:  # No dummy feature was included more than once\n",
    "                    dic['*'.join(sorted(term_names))] = product(term_facts)\n",
    "        return dic\n",
    "\n",
    "    \n",
    "class BenchmarkClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"\n",
    "    Clasificador \"benchmark\" con modelo nulo para p: un promedio móvil.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.sum_ = 0\n",
    "        self.n_ = 0\n",
    "    \n",
    "    def partial_fit(self, X, y):\n",
    "        self.sum_ += y.sum()\n",
    "        self.n_ += len(y)\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return self.predict_proba(X)[:, 1] >= 0.5\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        p = np.full(X.shape[0], self.sum_ / self.n_)\n",
    "        return np.column_stack([1 - p, p]) \n",
    "\n",
    "\n",
    "def product(iterable, start=1):\n",
    "    \"\"\"\n",
    "    Devuelve la productoria de los números en `iterable` con base `start`.\n",
    "    \"\"\"\n",
    "    return reduce(operator.mul, iterable, start)\n",
    "\n",
    "\n",
    "def split(seq, n):\n",
    "    \"\"\"\n",
    "    Divide la secuencia `seq` en partes de tamaño `n` o `n+1`, si es posible.\n",
    "    \"\"\"\n",
    "    m, k = divmod(len(seq), n)\n",
    "    i = 0\n",
    "    for _ in range(n):\n",
    "        j = i + m + (1 if k > 0 else 0)\n",
    "        yield seq[i:j]\n",
    "        i = j\n",
    "        k -= 1\n",
    "\n",
    "\n",
    "def loss(classifier, X, y):\n",
    "    \"\"\"\n",
    "    Calcula la pérdida apropiada de predecir con `classifier` sobre `X` vs `y`.\n",
    "    \"\"\"\n",
    "    if use_squared_loss:\n",
    "        return mean_squared_error(y, classifier.predict_proba(X)[:, 1])\n",
    "    else:\n",
    "        return log_loss(y, classifier.predict(X))\n",
    "\n",
    "\n",
    "def job(n_job):\n",
    "    \"\"\"\n",
    "    Crea un pipeline de clasificación para el split `n_job` de la grilla.\n",
    "    \n",
    "    Lee de a minibatches los archivos de entrada, alimentando progresivamente\n",
    "    al pipeline con ellos. Calcula el score medio usando validación progresiva.\n",
    "    El i-ésimo pipeline se almacena en un shelve bajo la clave f'{n_job}-{i}'.\n",
    "    Su score se guarda con esa mismo identificador bajo la clave 'scores'.\n",
    "    Los parámetros que controlan la operación se detallan en la sección\n",
    "    Configuración arriba.    \n",
    "    \"\"\"\n",
    "    for i, params in enumerate(list(split(grid, n_jobs))[n_job]):\n",
    "        extractor = Extractor(**params['extractor'])\n",
    "        vectorizer = Vectorizer(**params['vectorizer'])\n",
    "        sgd_classifier = SGDClassifier(**params['classifier'])\n",
    "        sgd_scores = []\n",
    "        bench_classifier = BenchmarkClassifier()\n",
    "        bench_scores = []\n",
    "        for in_path in in_paths:\n",
    "            for j in count(0, batch_size * n_batches):\n",
    "                batches = pd.read_csv(in_path,\n",
    "                                      nrows=batch_size * n_batches,\n",
    "                                      skiprows=range(1, j + 1))\n",
    "                if len(batches) == 0:\n",
    "                    break\n",
    "                for batch in split(batches, n_batches):\n",
    "                    X = extractor.transform(batch)\n",
    "                    X = vectorizer.transform(X)\n",
    "                    y = batch.loc[:, 'y']\n",
    "                    if j > 0:\n",
    "                        sgd_scores.append(-loss(sgd_classifier, X, y))\n",
    "                        bench_scores.append(-loss(bench_classifier, X, y))\n",
    "                    sgd_classifier.partial_fit(X, y, classes=[0, 1])\n",
    "                    bench_classifier.partial_fit(X, y)\n",
    "            key = f'{n_job}-{i}'\n",
    "        pipe = Pipeline([('extractor', extractor),\n",
    "                         ('vectorizer', vectorizer),\n",
    "                         ('classifier', sgd_classifier)])\n",
    "        from_scores = int(drop_scores * len(sgd_scores))\n",
    "        score = np.mean(sgd_scores[from_scores:])\n",
    "        bench_score = np.mean(bench_scores[from_scores:])\n",
    "        r2_score = abs((score - bench_score) / bench_score)\n",
    "        with lock: # Lockea el archivo ya que todos los procesos van a escribir en un  mismo archivo\n",
    "            with shelve.open(out_path) as out:\n",
    "                # Guardamos los scores bajo otra clave para no tener que cargar\n",
    "                # en memoria todos los estimadores al ordenarlos en results()\n",
    "                out[key] = pipe\n",
    "                scores = out['scores']\n",
    "                scores[key] = score, r2_score\n",
    "                out['scores'] = scores\n",
    "        print(f'Fitted {key} with score {score, r2_score} and params {params}\\n\\n')\n",
    "\n",
    "    \n",
    "def fit():\n",
    "    \"\"\"\n",
    "    Despacha jobs de aprendizaje a diferentes procesos y espera que finalicen. \n",
    "    \"\"\"\n",
    "    print(f'Fitting grid of size {len(grid)}\\n\\n')\n",
    "    with shelve.open(out_path, 'n') as out:  # Recrea la base\n",
    "        out['scores'] = {}\n",
    "    if n_jobs > 1:\n",
    "        procs = []\n",
    "        for n_job in range(n_jobs):\n",
    "            proc = mp.Process(target=job, args=[n_job])\n",
    "            proc.start()\n",
    "            procs.append(proc)\n",
    "        for proc in procs:\n",
    "            proc.join() #La funcion join se encarga de que los procesos terminen\n",
    "    else:\n",
    "        fit(0)\n",
    "\n",
    "\n",
    "def results(n=5):\n",
    "    \"\"\"\n",
    "    Lee y presenta los `n` mejores resultados del fit almacenados en el shelve de salida.\n",
    "    \"\"\"\n",
    "    with lock:\n",
    "        with shelve.open(out_path) as out:\n",
    "            rank = sorted(((s, k) for k, s in out['scores'].items()),\n",
    "                          reverse=True)\n",
    "            return [(s, out[k]) for s, k in rank[:n]]\n",
    "\n",
    "\n",
    "# Usamos este lock para garantizar que solo un proceso lee/escribe a la vez en el shelve\n",
    "lock = mp.Lock()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit y análisis de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting grid of size 144\n",
      "\n",
      "\n",
      "Fitted 0-0 with score (-0.19201208885367613, 0.023538565665445457) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 1048576, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.15, 'alpha': 0.0001}}\n",
      "\n",
      "\n",
      "Fitted 4-0 with score (-0.1907473375626859, 0.02997035267974086) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 1048576, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.15, 'alpha': 0.0001}}\n",
      "\n",
      "\n",
      "Fitted 3-0 with score (-0.18717844825509342, 0.048119641055686155) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 4194304, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.5, 'alpha': 0.01}}\n",
      "\n",
      "\n",
      "Fitted 7-0 with score (-0.18372455697053566, 0.0656841165941247) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 4194304, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.5, 'alpha': 0.01}}\n",
      "\n",
      "\n",
      "Fitted 0-1 with score (-0.18726744451354035, 0.04766705801941842) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 1048576, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.15, 'alpha': 0.001}}\n",
      "\n",
      "\n",
      "Fitted 4-1 with score (-0.1844382961613337, 0.0620544555756534) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 1048576, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.15, 'alpha': 0.001}}\n",
      "\n",
      "\n",
      "Fitted 1-0 with score (-0.18415652710245556, 0.0634873685814221) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 1048576, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.5, 'alpha': 0.01}}\n",
      "\n",
      "\n",
      "Fitted 2-0 with score (-0.1984838589169585, 0.009373080243952938) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 2097152, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.15, 'alpha': 0.0001}}\n",
      "\n",
      "\n",
      "Fitted 3-1 with score (-0.2158702008115272, 0.09778986923654076) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 4194304, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.5, 'alpha': 0.1}}\n",
      "\n",
      "\n",
      "Fitted 0-2 with score (-0.18762131246539004, 0.045867492117651176) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 1048576, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.15, 'alpha': 0.01}}\n",
      "\n",
      "\n",
      "Fitted 7-1 with score (-0.2118650706774833, 0.07742211458768984) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 4194304, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.5, 'alpha': 0.1}}\n",
      "\n",
      "\n",
      "Fitted 4-2 with score (-0.18420209946016855, 0.0632556141640617) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 1048576, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.15, 'alpha': 0.01}}\n",
      "\n",
      "\n",
      "Fitted 0-3 with score (-0.21959546440790692, 0.11673438599229194) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 1048576, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.15, 'alpha': 0.1}}\n",
      "\n",
      "\n",
      "Fitted 4-3 with score (-0.21707032154043449, 0.10389298292755673) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 1048576, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.15, 'alpha': 0.1}}\n",
      "\n",
      "\n",
      "Fitted 3-2 with score (-0.19077208378175473, 0.029844507850331554) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 4194304, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.85, 'alpha': 0.0001}}\n",
      "\n",
      "\n",
      "Fitted 7-2 with score (-0.18951563242198374, 0.03623408625791048) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 4194304, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.85, 'alpha': 0.0001}}\n",
      "\n",
      "\n",
      "Fitted 0-4 with score (-0.19018425230589708, 0.032833875704666844) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 1048576, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.5, 'alpha': 0.0001}}\n",
      "\n",
      "\n",
      "Fitted 5-0 with score (-0.17526304141881935, 0.10871444693217656) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 1048576, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.5, 'alpha': 0.01}}\n",
      "\n",
      "\n",
      "Fitted 6-0 with score (-0.19917778907081873, 0.012902004060217097) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 2097152, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.15, 'alpha': 0.0001}}\n",
      "\n",
      "\n",
      "Fitted 4-4 with score (-0.1889342563684072, 0.03919062560161679) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 1048576, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.5, 'alpha': 0.0001}}\n",
      "\n",
      "\n",
      "Fitted 1-1 with score (-0.19643922050898813, 0.0010247575404363387) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 1048576, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.5, 'alpha': 0.1}}\n",
      "\n",
      "\n",
      "Fitted 3-3 with score (-0.1873530229086692, 0.04723185624147597) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 4194304, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.85, 'alpha': 0.001}}\n",
      "\n",
      "\n",
      "Fitted 0-5 with score (-0.18720476637118288, 0.047985802475317973) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 1048576, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.5, 'alpha': 0.001}}\n",
      "\n",
      "\n",
      "Fitted 2-1 with score (-0.18214149042419955, 0.07373466924271545) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 2097152, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.15, 'alpha': 0.001}}\n",
      "\n",
      "\n",
      "Fitted 7-3 with score (-0.18447722057617044, 0.06185650871632266) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 4194304, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.85, 'alpha': 0.001}}\n",
      "\n",
      "\n",
      "Fitted 4-5 with score (-0.18431786723779506, 0.06266688680389508) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 1048576, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.5, 'alpha': 0.001}}\n",
      "\n",
      "\n",
      "Fitted 0-6 with score (-0.1873065654313171, 0.04746811186080506) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 1048576, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.5, 'alpha': 0.01}}\n",
      "\n",
      "\n",
      "Fitted 3-4 with score (-0.1872421952282545, 0.047795461150040776) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 4194304, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.85, 'alpha': 0.01}}\n",
      "\n",
      "\n",
      "Fitted 4-6 with score (-0.1838529653806508, 0.06503110635362262) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 1048576, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.5, 'alpha': 0.01}}\n",
      "\n",
      "\n",
      "Fitted 7-4 with score (-0.18368553106445773, 0.06588257957868242) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 4194304, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.85, 'alpha': 0.01}}\n",
      "\n",
      "\n",
      "Fitted 0-7 with score (-0.21995625582060027, 0.11856916057569128) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 1048576, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.5, 'alpha': 0.1}}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitted 4-7 with score (-0.2161587457900901, 0.0992572406157057) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 1048576, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.5, 'alpha': 0.1}}\n",
      "\n",
      "\n",
      "Fitted 3-5 with score (-0.2197339788564591, 0.1174387896468576) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 4194304, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.85, 'alpha': 0.1}}\n",
      "\n",
      "\n",
      "Fitted 1-2 with score (-0.19549610124948846, 0.005820911732485032) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 1048576, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.85, 'alpha': 0.0001}}\n",
      "\n",
      "\n",
      "Fitted 0-8 with score (-0.19096272861649197, 0.028874999472565492) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 1048576, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.85, 'alpha': 0.0001}}\n",
      "\n",
      "\n",
      "Fitted 2-2 with score (-0.18508557185597643, 0.058762789113536065) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 2097152, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.15, 'alpha': 0.01}}\n",
      "\n",
      "\n",
      "Fitted 7-5 with score (-0.21631646057587436, 0.10005928598098496) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 4194304, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.85, 'alpha': 0.1}}\n",
      "\n",
      "\n",
      "Fitted 4-8 with score (-0.19072654215181684, 0.03007610600415912) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 1048576, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.85, 'alpha': 0.0001}}\n",
      "\n",
      "\n",
      "Fitted 0-9 with score (-0.18724974908243475, 0.04775704665576787) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 1048576, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.85, 'alpha': 0.001}}\n",
      "\n",
      "\n",
      "Fitted 5-1 with score (-0.18764614936333976, 0.045741186148369826) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 1048576, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.5, 'alpha': 0.1}}\n",
      "\n",
      "\n",
      "Fitted 6-1 with score (-0.1739175969766156, 0.1155565922246685) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 2097152, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.15, 'alpha': 0.001}}\n",
      "\n",
      "\n",
      "Fitted 4-9 with score (-0.1843339919992282, 0.06258488567692796) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 1048576, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.85, 'alpha': 0.001}}\n",
      "\n",
      "\n",
      "Fitted 0-10 with score (-0.18712118420948545, 0.048410852574939836) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 1048576, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.85, 'alpha': 0.01}}\n",
      "\n",
      "\n",
      "Fitted 1-3 with score (-0.18270112419269832, 0.07088869847310005) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 1048576, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.85, 'alpha': 0.001}}\n",
      "\n",
      "\n",
      "Fitted 0-11 with score (-0.2190150246341328, 0.11378260802129027) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 1048576, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.85, 'alpha': 0.1}}\n",
      "\n",
      "\n",
      "Fitted 4-10 with score (-0.183763410309143, 0.06548653118701982) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 1048576, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.85, 'alpha': 0.01}}\n",
      "\n",
      "\n",
      "Fitted 3-6 with score (-0.20019213101074915, 0.018060355242599867) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 4194304, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.15, 'alpha': 0.0001}}\n",
      "\n",
      "\n",
      "Fitted 2-3 with score (-0.19736243674788256, 0.003670181503317286) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 2097152, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.15, 'alpha': 0.1}}\n",
      "\n",
      "\n",
      "Fitted 4-11 with score (-0.2154153748256109, 0.09547688968805573) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 1048576, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.85, 'alpha': 0.1}}\n",
      "\n",
      "\n",
      "Fitted 1-4 with score (-0.18496121401830576, 0.05939520050631659) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 1048576, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.85, 'alpha': 0.01}}\n",
      "\n",
      "\n",
      "Fitted 0-12 with score (-0.19606894122553378, 0.002907781897833605) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 1048576, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.15, 'alpha': 0.0001}}\n",
      "\n",
      "\n",
      "Fitted 7-6 with score (-0.20121898798954, 0.02328235060941586) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 4194304, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.15, 'alpha': 0.0001}}\n",
      "\n",
      "\n",
      "Fitted 2-4 with score (-0.19986983664249994, 0.016421354162108538) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 2097152, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.5, 'alpha': 0.0001}}\n",
      "\n",
      "\n",
      "Fitted 5-2 with score (-0.2019806424211805, 0.027155680581643363) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 1048576, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.85, 'alpha': 0.0001}}\n",
      "\n",
      "\n",
      "Fitted 3-7 with score (-0.18189253759357418, 0.07500069806165792) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 4194304, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.15, 'alpha': 0.001}}\n",
      "\n",
      "\n",
      "Fitted 6-2 with score (-0.17660504188571877, 0.10188981568833413) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 2097152, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.15, 'alpha': 0.01}}\n",
      "\n",
      "\n",
      "Fitted 1-5 with score (-0.19683772543472303, 0.0010018059623909212) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 1048576, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.85, 'alpha': 0.1}}\n",
      "\n",
      "\n",
      "Fitted 0-13 with score (-0.18191664768063207, 0.07487808822843846) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 1048576, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.15, 'alpha': 0.001}}\n",
      "\n",
      "\n",
      "Fitted 2-5 with score (-0.1819393434860663, 0.07476267060624603) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 2097152, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.5, 'alpha': 0.001}}\n",
      "\n",
      "\n",
      "Fitted 4-12 with score (-0.19640194747787287, 0.0012143064258324687) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 1048576, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.15, 'alpha': 0.0001}}\n",
      "\n",
      "\n",
      "Fitted 3-8 with score (-0.1852498707595223, 0.05792726076751489) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 4194304, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.15, 'alpha': 0.01}}\n",
      "\n",
      "\n",
      "Fitted 1-6 with score (-0.19220429034714304, 0.02256114102977597) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 2097152, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.15, 'alpha': 0.0001}}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitted 1-7 with score (-0.1871797487717107, 0.048113027387093346) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 2097152, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.15, 'alpha': 0.001}}\n",
      "\n",
      "\n",
      "Fitted 7-7 with score (-0.17377374280395919, 0.11628815060000673) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 4194304, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.15, 'alpha': 0.001}}\n",
      "\n",
      "\n",
      "Fitted 5-3 with score (-0.1743235218359699, 0.11349229526939077) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 1048576, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.85, 'alpha': 0.001}}\n",
      "\n",
      "\n",
      "Fitted 0-14 with score (-0.1849764729038675, 0.05931760271874535) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 1048576, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.15, 'alpha': 0.01}}\n",
      "\n",
      "\n",
      "Fitted 1-8 with score (-0.18751868423746232, 0.04638939939569703) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 2097152, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.15, 'alpha': 0.01}}\n",
      "\n",
      "\n",
      "Fitted 2-6 with score (-0.18485955928010864, 0.059912157183677185) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 2097152, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.5, 'alpha': 0.01}}\n",
      "\n",
      "\n",
      "Fitted 6-3 with score (-0.18804929017782004, 0.043691047220678646) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 2097152, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.15, 'alpha': 0.1}}\n",
      "\n",
      "\n",
      "Fitted 3-9 with score (-0.19682190361909355, 0.0009213454409957709) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 4194304, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.15, 'alpha': 0.1}}\n",
      "\n",
      "\n",
      "Fitted 1-9 with score (-0.2178112762249688, 0.10766104606543882) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 2097152, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.15, 'alpha': 0.1}}\n",
      "\n",
      "\n",
      "Fitted 1-10 with score (-0.19253130540761465, 0.020898133263424077) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 2097152, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.5, 'alpha': 0.0001}}\n",
      "\n",
      "\n",
      "Fitted 4-13 with score (-0.17399580191232633, 0.115158887558509) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 1048576, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.15, 'alpha': 0.001}}\n",
      "\n",
      "\n",
      "Fitted 0-15 with score (-0.19673956017846758, 0.0005025947538817678) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 1048576, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.15, 'alpha': 0.1}}\n",
      "\n",
      "\n",
      "Fitted 1-11 with score (-0.187179262450448, 0.04811550053324036) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 2097152, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.5, 'alpha': 0.001}}\n",
      "\n",
      "\n",
      "Fitted 2-7 with score (-0.19699185892622437, 0.0017856389548286276) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 2097152, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.5, 'alpha': 0.1}}\n",
      "\n",
      "\n",
      "Fitted 3-10 with score (-0.20249813584230014, 0.02978735013569036) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 4194304, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.5, 'alpha': 0.0001}}\n",
      "\n",
      "\n",
      "Fitted 1-12 with score (-0.18741256043759927, 0.046929083112748175) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 2097152, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.5, 'alpha': 0.01}}\n",
      "\n",
      "\n",
      "Fitted 5-4 with score (-0.17531395033705255, 0.10845555388218588) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 1048576, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.85, 'alpha': 0.01}}\n",
      "\n",
      "\n",
      "Fitted 7-8 with score (-0.1757717449969116, 0.10612747739041191) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 4194304, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.15, 'alpha': 0.01}}\n",
      "\n",
      "\n",
      "Fitted 0-16 with score (-0.19959474700812116, 0.015022408811533406) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 1048576, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.5, 'alpha': 0.0001}}\n",
      "\n",
      "\n",
      "Fitted 1-13 with score (-0.21854734562797415, 0.11140426551229414) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 2097152, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.5, 'alpha': 0.1}}\n",
      "\n",
      "\n",
      "Fitted 6-4 with score (-0.19956768899464647, 0.014884807544834651) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 2097152, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.5, 'alpha': 0.0001}}\n",
      "\n",
      "\n",
      "Fitted 2-8 with score (-0.19867196662495856, 0.010329686275686215) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 2097152, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.85, 'alpha': 0.0001}}\n",
      "\n",
      "\n",
      "Fitted 1-14 with score (-0.19012833420012507, 0.033118242559344556) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 2097152, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.85, 'alpha': 0.0001}}\n",
      "\n",
      "\n",
      "Fitted 3-11 with score (-0.18206083012831634, 0.07414486043787502) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 4194304, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.5, 'alpha': 0.001}}\n",
      "\n",
      "\n",
      "Fitted 4-14 with score (-0.17626777580896028, 0.10360495414149137) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 1048576, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.15, 'alpha': 0.01}}\n",
      "\n",
      "\n",
      "Fitted 1-15 with score (-0.18727260253403086, 0.04764082733719132) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 2097152, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.85, 'alpha': 0.001}}\n",
      "\n",
      "\n",
      "Fitted 0-17 with score (-0.1823227252241246, 0.07281301481073328) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 1048576, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.5, 'alpha': 0.001}}\n",
      "\n",
      "\n",
      "Fitted 1-16 with score (-0.1872155521962479, 0.04793095206315731) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 2097152, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.85, 'alpha': 0.01}}\n",
      "\n",
      "\n",
      "Fitted 2-9 with score (-0.1821806519821354, 0.07353551641196868) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 2097152, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.85, 'alpha': 0.001}}\n",
      "\n",
      "\n",
      "Fitted 5-5 with score (-0.18763438536454777, 0.045801010981287985) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 1048576, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.85, 'alpha': 0.1}}\n",
      "\n",
      "\n",
      "Fitted 1-17 with score (-0.21800984606929488, 0.10867085641729643) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 2097152, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.85, 'alpha': 0.1}}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitted 7-9 with score (-0.18770886773174755, 0.045422237126252436) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 4194304, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.15, 'alpha': 0.1}}\n",
      "\n",
      "\n",
      "Fitted 3-12 with score (-0.18454724651003807, 0.061500397680641444) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 4194304, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.5, 'alpha': 0.01}}\n",
      "\n",
      "\n",
      "Fitted 5-6 with score (-0.19147522517950813, 0.026268741022892308) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 2097152, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.15, 'alpha': 0.0001}}\n",
      "\n",
      "\n",
      "Fitted 6-5 with score (-0.17397333950223295, 0.11527311826819679) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 2097152, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.5, 'alpha': 0.001}}\n",
      "\n",
      "\n",
      "Fitted 5-7 with score (-0.18438465945892343, 0.062327220544157104) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 2097152, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.15, 'alpha': 0.001}}\n",
      "\n",
      "\n",
      "Fitted 4-15 with score (-0.18776264436735976, 0.04514876053914235) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 1048576, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.15, 'alpha': 0.1}}\n",
      "\n",
      "\n",
      "Fitted 2-10 with score (-0.1838454372384173, 0.06506939009193875) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 2097152, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.85, 'alpha': 0.01}}\n",
      "\n",
      "\n",
      "Fitted 5-8 with score (-0.18404717293691167, 0.06404348005323061) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 2097152, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.15, 'alpha': 0.01}}\n",
      "\n",
      "\n",
      "Fitted 3-13 with score (-0.1967490487060403, 0.000550847868040802) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 4194304, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.5, 'alpha': 0.1}}\n",
      "\n",
      "\n",
      "Fitted 5-9 with score (-0.21394532223820895, 0.08800106008476635) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 2097152, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.15, 'alpha': 0.1}}\n",
      "\n",
      "\n",
      "Fitted 2-11 with score (-0.19697689100543814, 0.0017095208443118168) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 2097152, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.85, 'alpha': 0.1}}\n",
      "\n",
      "\n",
      "Fitted 7-10 with score (-0.2047659471534969, 0.04132011507227123) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 4194304, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.5, 'alpha': 0.0001}}\n",
      "\n",
      "\n",
      "Fitted 5-10 with score (-0.19129519155576, 0.027184286973790824) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 2097152, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.5, 'alpha': 0.0001}}\n",
      "\n",
      "\n",
      "Fitted 6-6 with score (-0.17572683111569276, 0.1063558831805801) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 2097152, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.5, 'alpha': 0.01}}\n",
      "\n",
      "\n",
      "Fitted 2-12 with score (-0.1902319890204773, 0.03259111463130056) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 4194304, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.15, 'alpha': 0.0001}}\n",
      "\n",
      "\n",
      "Fitted 5-11 with score (-0.18433786989825454, 0.06256516494544657) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 2097152, 'degree': 1}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.5, 'alpha': 0.001}}\n",
      "\n",
      "\n",
      "Fitted 4-16 with score (-0.2059204735456834, 0.04719136257351906) and params {'extractor': {'features': ['x1', 'x2', 'x3']}, 'vectorizer': {'n_features': 1048576, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.5, 'alpha': 0.0001}}\n",
      "\n",
      "\n",
      "Fitted 3-14 with score (-0.19494130650915342, 0.008642274028697815) and params {'extractor': {'features': ['x1', 'x2']}, 'vectorizer': {'n_features': 4194304, 'degree': 2}, 'classifier': {'loss': 'log', 'max_iter': 1000, 'tol': 0.001, 'l1_ratio': 0.85, 'alpha': 0.0001}}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paulati/miniconda2/envs/dhds/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paulati/miniconda2/envs/dhds/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-4-7d05f51b95be>\", line 156, in job\n",
      "    out[key] = pipe\n",
      "  File \"/home/paulati/miniconda2/envs/dhds/lib/python3.7/shelve.py\", line 125, in __setitem__\n",
      "    self.dict[key.encode(self.keyencoding)] = f.getvalue()\n",
      "  File \"/home/paulati/miniconda2/envs/dhds/lib/python3.7/dbm/dumb.py\", line 208, in __setitem__\n",
      "    self._addkey(key, self._addval(val))\n",
      "  File \"/home/paulati/miniconda2/envs/dhds/lib/python3.7/dbm/dumb.py\", line 170, in _addval\n",
      "    f.write(val)\n",
      "OSError: [Errno 28] No space left on device\n",
      "Process Process-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paulati/miniconda2/envs/dhds/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paulati/miniconda2/envs/dhds/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-4-7d05f51b95be>\", line 156, in job\n",
      "    out[key] = pipe\n",
      "  File \"/home/paulati/miniconda2/envs/dhds/lib/python3.7/shelve.py\", line 125, in __setitem__\n",
      "    self.dict[key.encode(self.keyencoding)] = f.getvalue()\n",
      "  File \"/home/paulati/miniconda2/envs/dhds/lib/python3.7/dbm/dumb.py\", line 208, in __setitem__\n",
      "    self._addkey(key, self._addval(val))\n",
      "  File \"/home/paulati/miniconda2/envs/dhds/lib/python3.7/dbm/dumb.py\", line 170, in _addval\n",
      "    f.write(val)\n",
      "OSError: [Errno 28] No space left on device\n",
      "Process Process-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paulati/miniconda2/envs/dhds/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paulati/miniconda2/envs/dhds/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-4-7d05f51b95be>\", line 156, in job\n",
      "    out[key] = pipe\n",
      "  File \"/home/paulati/miniconda2/envs/dhds/lib/python3.7/shelve.py\", line 125, in __setitem__\n",
      "    self.dict[key.encode(self.keyencoding)] = f.getvalue()\n",
      "  File \"/home/paulati/miniconda2/envs/dhds/lib/python3.7/dbm/dumb.py\", line 208, in __setitem__\n",
      "    self._addkey(key, self._addval(val))\n",
      "  File \"/home/paulati/miniconda2/envs/dhds/lib/python3.7/dbm/dumb.py\", line 170, in _addval\n",
      "    f.write(val)\n",
      "OSError: [Errno 28] No space left on device\n",
      "Process Process-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paulati/miniconda2/envs/dhds/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paulati/miniconda2/envs/dhds/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-4-7d05f51b95be>\", line 156, in job\n",
      "    out[key] = pipe\n",
      "  File \"/home/paulati/miniconda2/envs/dhds/lib/python3.7/shelve.py\", line 125, in __setitem__\n",
      "    self.dict[key.encode(self.keyencoding)] = f.getvalue()\n",
      "  File \"/home/paulati/miniconda2/envs/dhds/lib/python3.7/dbm/dumb.py\", line 208, in __setitem__\n",
      "    self._addkey(key, self._addval(val))\n",
      "  File \"/home/paulati/miniconda2/envs/dhds/lib/python3.7/dbm/dumb.py\", line 170, in _addval\n",
      "    f.write(val)\n",
      "OSError: [Errno 28] No space left on device\n",
      "Process Process-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paulati/miniconda2/envs/dhds/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paulati/miniconda2/envs/dhds/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-4-7d05f51b95be>\", line 156, in job\n",
      "    out[key] = pipe\n",
      "  File \"/home/paulati/miniconda2/envs/dhds/lib/python3.7/shelve.py\", line 125, in __setitem__\n",
      "    self.dict[key.encode(self.keyencoding)] = f.getvalue()\n",
      "  File \"/home/paulati/miniconda2/envs/dhds/lib/python3.7/dbm/dumb.py\", line 208, in __setitem__\n",
      "    self._addkey(key, self._addval(val))\n",
      "  File \"/home/paulati/miniconda2/envs/dhds/lib/python3.7/dbm/dumb.py\", line 170, in _addval\n",
      "    f.write(val)\n",
      "OSError: [Errno 28] No space left on device\n",
      "Process Process-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paulati/miniconda2/envs/dhds/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/paulati/miniconda2/envs/dhds/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-4-7d05f51b95be>\", line 156, in job\n",
      "    out[key] = pipe\n",
      "  File \"/home/paulati/miniconda2/envs/dhds/lib/python3.7/shelve.py\", line 125, in __setitem__\n",
      "    self.dict[key.encode(self.keyencoding)] = f.getvalue()\n",
      "  File \"/home/paulati/miniconda2/envs/dhds/lib/python3.7/dbm/dumb.py\", line 208, in __setitem__\n",
      "    self._addkey(key, self._addval(val))\n",
      "  File \"/home/paulati/miniconda2/envs/dhds/lib/python3.7/dbm/dumb.py\", line 170, in _addval\n",
      "    f.write(val)\n",
      "OSError: [Errno 28] No space left on device\n"
     ]
    }
   ],
   "source": [
    "# Recordar que esta función queda corriendo en background\n",
    "\n",
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((-0.17377374280395919, 0.11628815060000673), Pipeline(memory=None,\n",
       "           steps=[('extractor', Extractor(features=['x1', 'x2', 'x3'])),\n",
       "                  ('vectorizer',\n",
       "                   Vectorizer(degree=2, n_features=4194304,\n",
       "                              num_types=[<class 'float'>,\n",
       "                                         <class 'numpy.float64'>])),\n",
       "                  ('classifier',\n",
       "                   SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
       "                                 early_stopping=False, epsilon=0.1, eta0=0.0,\n",
       "                                 fit_intercept=True, l1_ratio=0.15,\n",
       "                                 learning_rate='optimal', loss='log',\n",
       "                                 max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "                                 penalty='l2', power_t=0.5, random_state=None,\n",
       "                                 shuffle=True, tol=0.001, validation_fraction=0.1,\n",
       "                                 verbose=0, warm_start=False))],\n",
       "           verbose=False)),\n",
       " ((-0.1739175969766156, 0.1155565922246685), Pipeline(memory=None,\n",
       "           steps=[('extractor', Extractor(features=['x1', 'x2', 'x3'])),\n",
       "                  ('vectorizer',\n",
       "                   Vectorizer(degree=2, n_features=2097152,\n",
       "                              num_types=[<class 'float'>,\n",
       "                                         <class 'numpy.float64'>])),\n",
       "                  ('classifier',\n",
       "                   SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
       "                                 early_stopping=False, epsilon=0.1, eta0=0.0,\n",
       "                                 fit_intercept=True, l1_ratio=0.15,\n",
       "                                 learning_rate='optimal', loss='log',\n",
       "                                 max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "                                 penalty='l2', power_t=0.5, random_state=None,\n",
       "                                 shuffle=True, tol=0.001, validation_fraction=0.1,\n",
       "                                 verbose=0, warm_start=False))],\n",
       "           verbose=False)),\n",
       " ((-0.17397333950223295, 0.11527311826819679), Pipeline(memory=None,\n",
       "           steps=[('extractor', Extractor(features=['x1', 'x2', 'x3'])),\n",
       "                  ('vectorizer',\n",
       "                   Vectorizer(degree=2, n_features=2097152,\n",
       "                              num_types=[<class 'float'>,\n",
       "                                         <class 'numpy.float64'>])),\n",
       "                  ('classifier',\n",
       "                   SGDClassifier(alpha=0.001, average=False, class_weight=None,\n",
       "                                 early_stopping=False, epsilon=0.1, eta0=0.0,\n",
       "                                 fit_intercept=True, l1_ratio=0.5,\n",
       "                                 learning_rate='optimal', loss='log',\n",
       "                                 max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "                                 penalty='l2', power_t=0.5, random_state=None,\n",
       "                                 shuffle=True, tol=0.001, validation_fraction=0.1,\n",
       "                                 verbose=0, warm_start=False))],\n",
       "           verbose=False))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ojo que si n es grande se van a cargar muchos pipeline a la vez en memoria!\n",
    "\n",
    "results(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.05135134906205183, 1895073),\n",
       " (-0.17522086774407616, 3674509),\n",
       " (0.22589380820274818, 3540263),\n",
       " (0.35957813028630814, 610204),\n",
       " (-0.443522956457671, 2084643),\n",
       " (0.46683769893610566, 1019690),\n",
       " (0.6712174093200043, 969760),\n",
       " (-0.706163176665084, 477344),\n",
       " (-0.7528122945467871, 3270775),\n",
       " (0.8392415570481887, None)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = results(1)[0][1].named_steps['classifier']\n",
    "idx = list(best.coef_[0].nonzero()[0])\n",
    "coefs = list(best.coef_[0][idx]) + [best.intercept_[0]]\n",
    "idx = idx + [None]\n",
    "list(sorted(zip(coefs, idx), key=lambda coef_idx: abs(coef_idx[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
