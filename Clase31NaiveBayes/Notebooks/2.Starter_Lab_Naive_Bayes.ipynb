{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB: Naive Bayes\n",
    "\n",
    "El objetivo de este lab es armar una clasificador que puede diferenciar comentarios negativos y positivos de películas (extraidos de [IMDB](http://www.imdb.com/) con la mayor efectividad posible. Observen cómo el dataset tiene (en principio) dos campos:\n",
    "\n",
    "    + sentence: que contiene el texto del comentario acerca de la película\n",
    "    + sentiment: la clasificación del comentario como positivo ($sentiment=1$) o negativo($sentiment=0)\n",
    "\n",
    "#### Importamos el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  sentiment\n",
       "0  A very, very, very slow-moving, aimless movie ...          0\n",
       "1  Not sure who was more lost - the flat characte...          0\n",
       "2  Attempting artiness with black & white and cle...          0\n",
       "3       Very little music or anything to speak of.            0\n",
       "4  The best scene in the movie was when Gerardo i...          1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fuente: https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences\n",
    "import pandas as pd\n",
    "df = pd.read_csv('../Data/imdb_labelled.txt', names=[\"sentence\", 'sentiment'], sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorización de los features\n",
    "\n",
    "Al igual que lo que hicimos en la práctica guiada, vamos a implementar un enfoque usado en análisis de texto, conocido como \"bag of words\". La idea es que se pueden extrear features (predictores) de un cuerpo de texto basado en las palabras que lo conforman. Pero es necesario transformar y procesar las palabras en el texto para poder hacerlas inteligibles para un clasificador.\n",
    "\n",
    "El enfoque que utilizamos en la práctica guiada fue calcular el tf-idf para que las palabras muy frecuentes en todo el corpus redujeran su importancia.\n",
    "\n",
    "Otra posibilidad para deshacernos de términos que no aportan información es utilizar lo que se conoce como \"stop words\". Las \"stop words\" son listados de palabras que se construyen manualmente con los términos más frecuentes de cada idioma que no contienen información específica sobre la temática de la cual habla el texto.\n",
    "Scikit learn tiene un listado de stopwords en inglés. Si queremos clasificar texto en español o en otros idiomas, existen paquetes de python que nos pueden ayudar a construir la lista de stopwords, como por ejemplo: https://pypi.python.org/pypi/stop-words\n",
    "\n",
    "\n",
    "A diferencia de lo que hicimos en la práctica guiada, para realizar la vectorización vamos a usar un método de `sklearn` llamado [`CountVectorizer`](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer) \n",
    "\n",
    "**Hint:** pueden revisar [este ejemplo de uso y análisis de texto](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction) en `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementación, predicción y evaluación del modelo\n",
    "\n",
    "A continuación, les pedimos que implementen un clasificador de tipo Naive Bayes, que evalúen su performance sobre datos no observados y que construyan una matriz de confusión para evaluar específicamente en qué clase el modelo comete mayor cantidad de errores de predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
