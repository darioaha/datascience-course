{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7yO4fvwhyhvk"
   },
   "source": [
    "# PRÁCTICA GUIADA: Boosting en Scikit Learn\n",
    "\n",
    "## 1. Introducción\n",
    "En esta práctica vamos a comparar el rendimiento de los siguientes algoritmos:\n",
    "\n",
    "- AdaBoostClassifier()\n",
    "- GradientBoostingClassifier()\n",
    "\n",
    "\n",
    "Para ello vamos a comenzar con la lectura del dataset de aceptabilidad de autos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jScdVG1wyhvm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "buying           object\n",
       "maint            object\n",
       "doors            object\n",
       "persons          object\n",
       "lug_boot         object\n",
       "safety           object\n",
       "acceptability    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv('../Data/car.csv') # Revisar el path\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q3YsInLayhvs"
   },
   "source": [
    "Esta vez vamos a codificar los atributos usando un esquema One Hot, es decir, los consideraremos como variables categóricas. También vamos a codificar el target usando el `LabelEncoder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BnIuS5w9yhvu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lab_enc = LabelEncoder()\n",
    "lab_enc.fit(df['acceptability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FsgZYvLOyhvy",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying_high</th>\n",
       "      <th>buying_low</th>\n",
       "      <th>buying_med</th>\n",
       "      <th>buying_vhigh</th>\n",
       "      <th>maint_high</th>\n",
       "      <th>maint_low</th>\n",
       "      <th>maint_med</th>\n",
       "      <th>maint_vhigh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   buying_high  buying_low  buying_med  buying_vhigh  maint_high  maint_low  \\\n",
       "0            0           0           0             1           0          0   \n",
       "1            0           0           0             1           0          0   \n",
       "2            0           0           0             1           0          0   \n",
       "3            0           0           0             1           0          0   \n",
       "4            0           0           0             1           0          0   \n",
       "\n",
       "   maint_med  maint_vhigh  \n",
       "0          0            1  \n",
       "1          0            1  \n",
       "2          0            1  \n",
       "3          0            1  \n",
       "4          0            1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = lab_enc.transform(df['acceptability'])\n",
    "X = pd.get_dummies(df.drop('acceptability', axis=1))\n",
    "\n",
    "X.iloc[:,0:8].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos el split entre train y test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_NC7Ei-ryhv1"
   },
   "source": [
    "Para que los resultados sean consistentes hay que exponer los modelos exactamente al mismo esquema de validación cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j0pXpjNFyhv3"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "cv = StratifiedKFold(n_splits=3, random_state=41, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nxxMJeMYyhv5"
   },
   "source": [
    "## 2. Comparando la performance de los árboles de decisión y boosting\n",
    " \n",
    "Ahora vamos a inicializar el clasificador de árbol de decisión, evaluar su rendimiento y compararlo con la perfomance de los modelos de boosting. Para ello, vamos a usar los siguientes métodos:\n",
    "\n",
    "### `AdaBoostClassifier()`\n",
    "\n",
    "La idea central de AdaBoost es construir un ensamble de week learners y, en cada iteración ir incrementando el peso de los casos mal clasificados. La implementación den Scikit-Learn toma los siguientes parámetros:\n",
    "\n",
    "* `base_estimator`: análogo al caso de `BaggingClassifier()`, el estimador sobre el cual se va a construir el ensamble. Por efecto, son árboles de decisión.\n",
    "* `n_estimators`: el máximo de iteraciones\n",
    "* `learning_rate`: el peso que va a tener la predicción de cada árbol en el ensamble final\n",
    "\n",
    "\n",
    "### `GradientBoostingClassifier()`\n",
    "\n",
    "Se trata de una generalización del algoritmo general de Boosting para cualquier tipo de función de pérdida diferenciable. En cada etapa, se fitea un árbol de decisión pero se realiza sobre los residuos del árbol anterior. Es decir, se busca corregir las estimaciones entrenando nuevos clasificadores sobre los \"residuos\" (la diferencia entre el valor observado y el valor predico ($y - \\hat{y}$)\n",
    "\n",
    "Los argumentos que toma como input son ya conocidos:\n",
    "\n",
    "* `learning_rate`: el peso que va a tener la predicción de cada árbol en el ensamble final\n",
    "\n",
    "* `n_estimators`: el máximo de iteraciones\n",
    "* `criterion`: define el criterio de impureza para evaluar la calidad de las particiones\n",
    "* `max_features`: la cantidad de features que extraerá para entrenar cada `base_estimator`. Por default es igual a `sqrt(X.shape[1])`\n",
    "* `bootstrap` y `bootstrap_features`: controla si tanto los n_samples como las features son extraidos con reposición.\n",
    "* `max_depth`: la pronfundidad máxima del árbol\n",
    "* `min_samples_leaf`: el número mínimo de n_samples para constituir una hoja del árbol (nodo terminal)\n",
    "* `min_samples_split`: el número mínimo de n_samples para realizar un split.\n",
    "\n",
    "\n",
    "Para comparar los diferentes algoritmos armamos la siguiente función. Toma como input un estimador y un string con el nombre que le quieran poner, y ejecuta un `cross_val_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V7Br9N3Jyhv6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento de Árbol de decisión:\t0.944 ± 0.008\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def evaluar_rendimiento(modelo, nombre, X_train, y_train, cv):\n",
    "    s = cross_val_score(modelo, X_train, y_train, cv=cv, n_jobs=-1)\n",
    "    print(\"Rendimiento de {}:\\t{:0.3} ± {:0.3}\".format( \\\n",
    "        nombre, s.mean().round(3), s.std().round(3)))\n",
    "    \n",
    "    \n",
    "dt = DecisionTreeClassifier(class_weight='balanced', random_state=1)\n",
    "\n",
    "evaluar_rendimiento(dt,\"Árbol de decisión\", X_train, y_train, cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probemos ahora los modelos de *boosting* AdaBoost y GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento de AdaBoostClassifier:\t0.837 ± 0.033\n",
      "Rendimiento de GradientBoostingClassifier:\t0.973 ± 0.009\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "ab = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1, random_state=1), n_estimators=100)\n",
    "gb = GradientBoostingClassifier()\n",
    "evaluar_rendimiento(ab, \"AdaBoostClassifier\",  X_train, y_train, cv)\n",
    "evaluar_rendimiento(gb, \"GradientBoostingClassifier\", X_train, y_train, cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puede verse, entonces, que AdaBoost performa bastante peor (al menos utilizando los parámetros por defecto). De esta forma, podríamos tratar de tunear los hiperparámetros para hacerlo funcionar mejor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params_ab = {\"n_estimators\": [100, 500],\n",
    "          \"learning_rate\":[0.01, 0.1, 1.0],\n",
    "        \"base_estimator__max_depth\": [1, 2, 3]}\n",
    "\n",
    "grid_ab = GridSearchCV(AdaBoostClassifier(base_estimator=DecisionTreeClassifier()), \n",
    "                       param_grid=params_ab, cv=cv, verbose=1, n_jobs=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=3)]: Done  54 out of  54 | elapsed:   15.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=41, shuffle=True),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                                          base_estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                                                criterion='gini',\n",
       "                                                                                max_depth=None,\n",
       "                                                                                max_features=None,\n",
       "                                                                                max_leaf_nodes=None,\n",
       "                                                                                min_impurity_decrease=0.0,\n",
       "                                                                                min_impurity_split=None,\n",
       "                                                                                min_samples_leaf=1,\n",
       "                                                                                m...es_split=2,\n",
       "                                                                                min_weight_fraction_leaf=0.0,\n",
       "                                                                                presort=False,\n",
       "                                                                                random_state=None,\n",
       "                                                                                splitter='best'),\n",
       "                                          learning_rate=1.0, n_estimators=50,\n",
       "                                          random_state=None),\n",
       "             iid='warn', n_jobs=3,\n",
       "             param_grid={'base_estimator__max_depth': [1, 2, 3],\n",
       "                         'learning_rate': [0.01, 0.1, 1.0],\n",
       "                         'n_estimators': [100, 500]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_ab.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                   base_estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                         criterion='gini',\n",
       "                                                         max_depth=3,\n",
       "                                                         max_features=None,\n",
       "                                                         max_leaf_nodes=None,\n",
       "                                                         min_impurity_decrease=0.0,\n",
       "                                                         min_impurity_split=None,\n",
       "                                                         min_samples_leaf=1,\n",
       "                                                         min_samples_split=2,\n",
       "                                                         min_weight_fraction_leaf=0.0,\n",
       "                                                         presort=False,\n",
       "                                                         random_state=None,\n",
       "                                                         splitter='best'),\n",
       "                   learning_rate=0.01, n_estimators=500, random_state=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_ab.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento de AdaBoostClassifier + GS:\t0.935 ± 0.005\n"
     ]
    }
   ],
   "source": [
    "evaluar_rendimiento(grid_ab.best_estimator_,  \"AdaBoostClassifier + GS\", X_train, y_train, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_gb = {'n_estimators':[100, 500] , \n",
    "             'learning_rate':[0.001, 0.001, 0.1, 1.0],\n",
    "            'max_depth' : [1, 2, 3, 4]}\n",
    "\n",
    "grid_gb = GridSearchCV(gb, param_grid=params_gb, cv=cv, verbose=1, n_jobs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:   29.8s\n",
      "[Parallel(n_jobs=3)]: Done  96 out of  96 | elapsed:  1.1min finished\n",
      "C:\\Users\\mbeati\\AppData\\Local\\Continuum\\anaconda3\\envs\\dsdh2\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=41, shuffle=True),\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=GradientBoostingClassifier(criterion='friedman_mse',\n",
       "                                                  init=None, learning_rate=0.1,\n",
       "                                                  loss='deviance', max_depth=3,\n",
       "                                                  max_features=None,\n",
       "                                                  max_leaf_nodes=None,\n",
       "                                                  min_impurity_decrease=0.0,\n",
       "                                                  min_impurity_split=None,\n",
       "                                                  min_samples_leaf=1,\n",
       "                                                  min_samples_split=2,...\n",
       "                                                  n_estimators=100,\n",
       "                                                  n_iter_no_change=None,\n",
       "                                                  presort='auto',\n",
       "                                                  random_state=None,\n",
       "                                                  subsample=1.0, tol=0.0001,\n",
       "                                                  validation_fraction=0.1,\n",
       "                                                  verbose=0, warm_start=False),\n",
       "             iid='warn', n_jobs=3,\n",
       "             param_grid={'learning_rate': [0.001, 0.001, 0.1, 1.0],\n",
       "                         'max_depth': [1, 2, 3, 4],\n",
       "                         'n_estimators': [100, 500]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "                           n_iter_no_change=None, presort='auto',\n",
       "                           random_state=None, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_gb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento de GradientBoostingClassifier + GS:\t0.987 ± 0.007\n"
     ]
    }
   ],
   "source": [
    "evaluar_rendimiento(grid_gb.best_estimator_, \"GradientBoostingClassifier + GS\", X_train, y_train, cv)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "1.PRACTICA_GUIADA_RandomForest_ExtraTrees..ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
