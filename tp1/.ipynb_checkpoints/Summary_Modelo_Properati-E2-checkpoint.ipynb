{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_principales = ['price_aprox_usd','property_type','surface_covered_in_m2','provincia']\n",
    "df_reg = df[columnas_principales]\n",
    "df_modelo= df_reg.dropna(axis =0 , how = 'any', subset = columnas_principales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reviso distribución de variable dependiente\n",
    "\n",
    "sns.distplot(df_modelo['price_aprox_usd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies = pd.get_dummies(df_modelo, columns = [ 'provincia', 'property_type'], drop_first = True)\n",
    "df_dummies.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(df_dummies.price_aprox_usd)\n",
    "\n",
    "x= df_dummies.drop(columns=['price_aprox_usd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reviso la varianza para ver si es necesario normalizar\n",
    "print([x[col].var() for col in x.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizacion por std\n",
    "stdscaler = preprocessing.StandardScaler()\n",
    "xs2 = stdscaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convierto en Dataframe\n",
    "X = pd.DataFrame(xs2, columns=x.columns)\n",
    "X.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviso varianza despues de normalizar y veo que todas las variables quedaron con varianza 1\n",
    "print([X[col].var() for col in X.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#estudiamos VIF para cuantificar la intensidad de la multicolinealidad\n",
    "#Si VIF>10, la multicolinealidad es alta\n",
    "\n",
    "import statsmodels.stats.outliers_influence as oi\n",
    "\n",
    "for i in range(len(X.columns)):\n",
    "    vif_col = oi.variance_inflation_factor(np.matrix(X), i)\n",
    "    print('columna ' + str(i) + \" \" + str(vif_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "#agrego el intercepto\n",
    "X_intercept = sm.add_constant(X)\n",
    "\n",
    "y.index = range(y.shape[0])\n",
    "\n",
    "# Fit and summarize OLS model (OLS = ordinary least square linear regression) Veo las descritivas del modelo\n",
    "model_intercept = sm.OLS(y, X_intercept)\n",
    "model_intercept = model_intercept.fit()\n",
    "print (model_intercept.summary())\n",
    "predictions_intercept = model_intercept.predict(X_intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculo de residuos\n",
    "\n",
    "predictions_intercept_df = pd.DataFrame(predictions_intercept, columns=['price_aprox_usd'])\n",
    "residuos_intercept = y - predictions_intercept_df\n",
    "print(residuos_intercept.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verifico la distribución y que la media de los residuos sea cero\n",
    "sns.distplot(residuos_intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verifico homocedasticidad con base en p_value\n",
    "#supuesto: Para cualquier valor de la variable explicativa, el error tienen la misma varianza\n",
    "import statsmodels.stats.api as sms\n",
    "\n",
    "resids_standardized = model_intercept.get_influence().resid_studentized_internal\n",
    "\n",
    "resids = model_intercept.resid\n",
    "\n",
    "bp_test = pd.DataFrame(sms.het_breuschpagan(resids, model_intercept.model.exog), \n",
    "                       columns=['value'],\n",
    "                       index=['Lagrange multiplier statistic', 'p-value', 'f-value', 'f p-value'])\n",
    "\n",
    "\n",
    "gq_test = pd.DataFrame(sms.het_goldfeldquandt(resids, model_intercept.model.exog)[:-1],\n",
    "                       columns=['value'],\n",
    "                       index=['F statistic', 'p-value'])\n",
    "\n",
    "print('\\n Breusch-Pagan test ----')\n",
    "print(bp_test)\n",
    "print('\\n Goldfeld-Quandt test ----')\n",
    "print(gq_test)\n",
    "#Si todo es consistente los dos test deberian dar el mismo resultado (significativo o no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vemos los gráficos de los residuos, no obtengo una linea horizontal (supuesto de homocedasticidad)\n",
    "fig, ax = plt.subplots(1,2)\n",
    "\n",
    "fitted_vals = predictions_intercept\n",
    "\n",
    "sns.regplot(x=fitted_vals, y=resids, lowess=True, ax=ax[0], line_kws={'color': 'red'})\n",
    "ax[0].set_title('Residuals vs Fitted', fontsize=16)\n",
    "ax[0].set(xlabel='Fitted Values', ylabel='Residuals')\n",
    "\n",
    "sns.regplot(x=fitted_vals, y=np.sqrt(np.abs(resids_standardized)), lowess=True, ax=ax[1], line_kws={'color': 'red'})\n",
    "ax[1].set_title('Scale-Location', fontsize=16)\n",
    "ax[1].set(xlabel='Fitted Values', ylabel='sqrt(abs(Residuals))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifico si los residuos tienen distribucion normal. (con un grafico de datos reales vs simulados). Deberia dar una recta.\n",
    "#el grafico es en quantiles\n",
    "\n",
    "sm.ProbPlot(model_intercept.resid).qqplot(line='s');\n",
    "plt.title('Q-Q plot');\n",
    "\n",
    "jb = stats.jarque_bera(model_intercept.resid)\n",
    "sw = stats.shapiro(model_intercept.resid)\n",
    "ad = stats.anderson(model_intercept.resid, dist='norm')\n",
    "ks = stats.kstest(model_intercept.resid, 'norm')\n",
    "\n",
    "print(f'Jarque-Bera test ---- statistic: {jb[0]:.4f}, p-value: {jb[1]}')\n",
    "print(f'Shapiro-Wilk test ---- statistic: {sw[0]:.4f}, p-value: {sw[1]:.4f}')\n",
    "print(f'Kolmogorov-Smirnov test ---- statistic: {ks.statistic:.4f}, p-value: {ks.pvalue:.4f}')\n",
    "print(f'Anderson-Darling test ---- statistic: {ad.statistic:.4f}, 5% critical value: {ad.critical_values[2]:.4f}')\n",
    "print('If the returned AD statistic is larger than the critical value, then for the 5% significance level, the null hypothesis that the data come from the Normal distribution should be rejected.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verifico el R2 y el error de la regresion\n",
    "print('r2: ' + str(model_intercept.rsquared))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divido los datos en train and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=53)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el RMSE\n",
    "y_pred_tr_lm = lm.predict(X_train)\n",
    "#definimos la raiz del error cuadratico medio\n",
    "rmse = lambda y, y_pred: np.sqrt(mean_squared_error(y, y_pred))\n",
    "print(\" Score Test Lineal: %.2f\\n\" % lm.score(X_train, y_train))\n",
    "print(\" Train RMSE lineal   : %.2f \\n\" % rmse(y_train,y_pred_tr_lm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hcemos el calculo con los datos de test (score y error cuadratico medio)\n",
    "y_pred_lm = lm.predict(X_test)\n",
    "print(\" Score Test Lineal: %.2f\\n\" % lm.score(X_test, y_test))\n",
    "print(\" Test RMSE lineal= %.2f\\n\" % rmse(y_test, y_pred_lm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hago lo mismo con ridge y lasso\n",
    "y_pred_ridge = lm_ridge_cv.predict(X_test)\n",
    "y_pred_lasso = lm_lasso_cv.predict(X_test)\n",
    "\n",
    "lm_ridge_cv.fit(X_train, y_train)\n",
    "lm_lasso_cv.fit(X_train, y_train)\n",
    "# revisos los alfas\n",
    "print('Alpha Ridge:',lm_ridge_cv.alpha_,'\\n'\n",
    "      'Alpha LASSO:',lm_lasso_cv.alpha_,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos el R2 para ridge y Lasso\n",
    "\n",
    "print(\"Score Train Ridge : %.2f\\n\" % lm_ridge_cv.score(X_train, y_train),\n",
    "      \"Score Train Lasso : %.2f\\n\" %  lm_lasso_cv.score(X_train, y_train))\n",
    "\n",
    "# Calculamos el RMSE\n",
    "\n",
    "\n",
    "y_pred_tr_ridge = lm_ridge_cv.predict(X_train)\n",
    "y_pred_tr_lasso = lm_lasso_cv.predict(X_train)\n",
    "\n",
    "\n",
    "print(\" Train RMSE lineal   : %.2f \\n\" % rmse(y_train,y_pred_tr_lm),\n",
    "      \"Train RMSE Ridge    : %.2f \\n\" % rmse(y_train,y_pred_tr_ridge),\n",
    "      \"Train RMSE Lasso    : %.2f \\n\" % rmse(y_train,y_pred_tr_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos las predicciones sobre la matriz de predictores del Test \n",
    "\n",
    "y_pred_ridge = lm_ridge_cv.predict(X_test)\n",
    "y_pred_lasso = lm_lasso_cv.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Score Test Ridge : %.2f\\n\" % lm_ridge_cv.score(X_test, y_test),\n",
    "      \"Score Test Lasso : %.2f\\n\" %  lm_lasso_cv.score(X_test, y_test))\n",
    "\n",
    "# Testeo final del modelo sobre Test Set\n",
    "\n",
    "print(\"Test RMSE Ridge = %.2f\\n\" %  rmse(y_test, y_pred_ridge),\n",
    "      \"Test RMSE Lasso = %.2f\" %  rmse(y_test, y_pred_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deben compararse el score, el r2 y el rsme de los tres modelos para sacar alguna conclusión y ponerla en la ppt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
