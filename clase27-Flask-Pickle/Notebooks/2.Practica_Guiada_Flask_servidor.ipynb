{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from flask import Flask, jsonify, request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Flask : usando JSON\n",
    "\n",
    "Recordemos estos argumentos para el open :\n",
    "\n",
    "    'math_model.pkl' > El archivo que contiene el modelo serializado.\n",
    "\n",
    "    'rb' > Es la forma de lectura en binario.\n",
    "\n",
    "Para deserializar un pickle, debemos mantener abierto el archivo que contiene la data en forma de lectura binaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNetCV(alphas=array([1.000e-03, 1.020e-01, 2.030e-01, 3.040e-01, 4.050e-01, 5.060e-01,\n",
       "       6.070e-01, 7.080e-01, 8.090e-01, 9.100e-01, 1.011e+00, 1.112e+00,\n",
       "       1.213e+00, 1.314e+00, 1.415e+00, 1.516e+00, 1.617e+00, 1.718e+00,\n",
       "       1.819e+00, 1.920e+00, 2.021e+00, 2.122e+00, 2.223e+00, 2.324e+00,\n",
       "       2.425e+00, 2.526e+00, 2.627e+00, 2.728e+00, 2.829e+00, 2.930e+00,\n",
       "       3.031e+00, 3.132e+00, 3.2...\n",
       "       8.485e+00, 8.586e+00, 8.687e+00, 8.788e+00, 8.889e+00, 8.990e+00,\n",
       "       9.091e+00, 9.192e+00, 9.293e+00, 9.394e+00, 9.495e+00, 9.596e+00,\n",
       "       9.697e+00, 9.798e+00, 9.899e+00, 1.000e+01]),\n",
       "             copy_X=True, cv=3, eps=0.001, fit_intercept=True, l1_ratio=0.5,\n",
       "             max_iter=1000, n_alphas=100, n_jobs=-1, normalize=False,\n",
       "             positive=False, precompute='auto', random_state=None,\n",
       "             selection='cyclic', tol=0.0001, verbose=1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vamos a cargar uno de los modelos en memoria a partir de un archivo pickle\n",
    "# el archivo se mantiene abierto solo en el ambito del with, despues del bloque se cierra automaticamente.\n",
    "with open('math_model.pkl', 'rb') as f_math:\n",
    "    \n",
    "    modelo_matematicas = pickle.load(f_math)\n",
    "\n",
    "modelo_matematicas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poner el modelo a disposici贸n, debemos tener en cuenta como vamos a definir la comunicaci贸n\n",
    "\n",
    "En nuestro caso vamos a responder a un **POST requests** cuyo contenido va a ser un json como este :\n",
    "\n",
    "**{ \"model\" : \"math\",**\n",
    " \n",
    " **\"dummies\": \\[\"1\", \"0\", \"1\", \"0\", \"0\", \"0\", \"0\", \"1\", \"1\", \"0\", \"0\", \"0\", \"1\", \"0\", \"1\", \"0\", \"1\"\\] }**\n",
    " \n",
    " En donde cada posicion de un elemento en el array representa una dummy ordenada.\n",
    "\n",
    "Para poder trabajar con este json debemos parsear el contenido del post requests (o sea el contenido que nos va a solicitar un potencial cliente).\n",
    "\n",
    "Vamos a utilizar la funcionalidad dada por la clase _requests_ de flask para tratar la petici贸n.\n",
    "\n",
    "La clase _requests_ tiene un metodo *get_json* que permite parsear el contenido de un request especificado como json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://flask.pocoo.org/docs/1.0/quickstart/\n",
    "\n",
    "app = Flask('Predictor de examenes')\n",
    "\n",
    "# tell Flask what URL should trigger our function\n",
    "@app.route('/',methods=['POST'])\n",
    "def predict():\n",
    "    \n",
    "    \n",
    "    # https://tedboy.github.io/flask/generated/generated/flask.Request.get_json.html\n",
    "    \n",
    "    # obtengo los datos del request post.\n",
    "    # notar que en este contexto request contiene la informacion \n",
    "    # que viene de la peticion externa (el metodo get_json lo transforma en un diccionario)\n",
    "    data = request.get_json(force=True)\n",
    "    \n",
    "    \n",
    "    # transformamos el dato del json (un array de string) en un array de enteros de numpy\n",
    "    # para que lo entienda el modelo, notar la forma del array y la transformacion de los tipos de datos\n",
    "    X_para_prediccion = np.array(data['dummies']).reshape(1, -1).astype('int')\n",
    "    \n",
    "    # implementamos una logica en donde elegimos un modelo (podrian ser los otros modelos, lect/escritura)\n",
    "    if data['model'] == 'math':\n",
    "        \n",
    "        # asignamos el array de numpy que nos devuelve una prediccion\n",
    "        output = modelo_matematicas.predict(X_para_prediccion)\n",
    "                \n",
    "        # esta prediccion es un array de un solo elemento\n",
    "        prediccion = output[0]\n",
    "        \n",
    "        # Le damos forma de un diccionario para poder hacer el traspaso a json trivialmente\n",
    "        output = {'prediccion': prediccion}\n",
    "        \n",
    "        # en esta linea, transformamos el diccionario en json con jsonify (funcionalidad de flask)\n",
    "        # y respondemos el request con un json mediante este return\n",
    "        # este json es incorporado en el cuerpo de la respuesta\n",
    "        return jsonify(output)\n",
    "    \n",
    "    \n",
    "@app.route('/hola',methods=['GET'])\n",
    "def saludar():\n",
    "    return \"hola paula\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En este punto vamos a poner a escuchar al servidor en 0.0.0.0:5000\n",
    "\n",
    "Entre las cosas que vamos a ver por la salida estandar, va a ser la interaccion de nuestro servidor, con las peticiones externas. \n",
    "\n",
    "cuando sea ejecutada la proxima celda, la notebook se va a encontrar en estado de ejecuci贸n respondiendo peticiones, en este estado se le puede realizar un requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"Predictor de examenes\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [08/Jul/2019 13:09:40] \"GET /hola HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Jul/2019 13:09:50] \"GET /hola HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Jul/2019 13:09:50] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [08/Jul/2019 13:10:27] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Jul/2019 13:10:54] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Jul/2019 13:11:37] \"POST / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# el puerto 5000 es por default\n",
    "app.run(host='0.0.0.0', port=5000 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
